{"cells":[{"cell_type":"markdown","source":["## Fine Tune Gemma2 2b quantized model on Ecommerce Question Answer"],"metadata":{"id":"Tb4mHTwDpFon"}},{"cell_type":"markdown","metadata":{"id":"IqM-T1RTzY6C"},"source":["To install Unsloth on own computer,the installation instructions Github page [here](https://github.com/unslothai/unsloth#installation-instructions---conda).\n","\n"," [data prep](#Data), [train](#Train),  [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1735142158143,"user_tz":-345,"elapsed":37525,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[],"source":["%%capture\n","!pip install unsloth\n","# Also get the latest nightly Unsloth!\n","!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n","\n","# Install Flash Attention 2 for softcapping support\n","import torch\n","if torch.cuda.get_device_capability()[0] >= 8:\n","    !pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""]},{"cell_type":"markdown","metadata":{"id":"r2v_X2fA0Df5"},"source":["* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n","* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n","* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n","* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","* [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348,"referenced_widgets":["ad63e965f2154fecb67a15647a841477","bafcc60b72e24c34afb6a1a19959ccee","08e0441e5d2f443db4f0a48a81cc0838","9d1be81c03e943a6ad24e5e1b9397424","b2d5b1277b92456d833deb10824b992a","bf202bd778924e70aeda28e16fa4ec4a","e5444f22168942f9a54d4b47a85ab583","905525b6561d4155a714f6b33697f7e7","c187db8dee5e44a487f8b1bb5e20c3e6","da8b59241d424192a9992980666481ee","839cb8f5c7974a139e7627057d1a130e","90d1a138d924496990ff34388bb0dc47","777ca5ac8e384fed87ae01694711981b","1589ea0d7126417893c1e08bfc10a2ed","71c9c71aa2ab4419b1f5b6e07d6b6012","22a05c8895244b44b84ba530d5c12046","36ee3488206f4861bccfb5a34a4e1210","2f5bef8c9dca48ef90878782be2321a6","86bfc2d88ebc411abc173e050f07ccfa","dab428459ce64f0e8c4f457c17ea92b6","c88dfef5527942869312a014e7fcb459","ebb9264d06fd4823970d5f780bbf0d83","265a41094c0f43e98d300e826b26d6c9","5b4c36996f40468db0e66f51ce9090f6","1910318f2d88454eb7b81fbddbc97bb3","204c8ad45e754a03b85dd64023e81c4a","c58272d80f224c30b5a03f183158bff9","fd5719522d854735b9729c1c28b7ae77","51cf83e6bc474db7970a6dd3a683b78f","48e9d677229b4dbc91de94dc4c3ca967","67176738d3a64f109d4184a99b5ad794","d04e8041384a402f8875b91d560a0793","16841c3d1d9947a68cdcb218cf2515fa","adcb10daa0f641baae1bd60dce22c06a","8508ba2db36646a5a7002fec07aaee52","5aecf2fb3d2842ed8c340e6d0e2d581b","8935500a52ec4389961113f79be6bf33","f26bf59b11d04016a98b9b481e04a69e","e2855683718f4501be28ca640378a41d","6175601dfa7e441f851ff3efdcf8c8d6","9b5fb1a5b54f41b4ac79ba264fda87fa","f4c1d8be6b984dffa9de1887b74fd539","f372a3fddf9243dfae57b64beea0053c","d6441cbf010a4ff1a38e12bf200215ba","28ab66a19dfa41c4af2aeb7328ef4b87","f6742a31daed4f0bb4bdad685174b751","d4034e0067e847ac9789d8a009ec90bd","af55ff1d963d49f38ffdd870c0f0f171","a596829c63f4427f96864851b8b325e5","8e10d59cb05b4a988570a42655235782","cad79e0205a74378b75d5624653d0c3a","07d9a41595c34e619f3154783432a6fb","56d0eb658166466cbe5601cebb9b987a","3148bbbc46cc4c5b84497a2e0d83d783","9ec0f07db1b841ad994a96a2148b000a","9ee1f440dcce41acbc9848a1643c2cf7","fbbd9836d26e45459002349733936536","74eac32a118b49a995396ff0afb39019","1ad01c134f9849578c51612b1e4bfedd","ed225c34732748dda669f58e83d5247c","fc85c2b4200941bcbee84700fa3c6b9c","4b69fcde9d884cb6851c2250f19440b0","e34c45f73226425b80c796e6a946d200","5fc58f79e32d4f869a6175b09856dcbc","8eabcdbc67794dfb9f6a354ab2d15e20","867f2304fd9d40e09308625298572833"]},"executionInfo":{"elapsed":69931,"status":"ok","timestamp":1735142246496,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"QmUBVEnvCDJv","outputId":"d3425455-4534-4795-8587-a332ceadffe6"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2024.12.9: Fast Gemma2 patching. Transformers: 4.47.1.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.22G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad63e965f2154fecb67a15647a841477"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90d1a138d924496990ff34388bb0dc47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"265a41094c0f43e98d300e826b26d6c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adcb10daa0f641baae1bd60dce22c06a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28ab66a19dfa41c4af2aeb7328ef4b87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ee1f440dcce41acbc9848a1643c2cf7"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","    \"unsloth/gemma-2-2b-bnb-4bit\",             # New small Gemma model!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/gemma-2-2b\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6575,"status":"ok","timestamp":1735142292591,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"6bZsfBuZDeCL","outputId":"e16b7277-946c-477a-9abc-0d13a4319feb"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.12.9 patched 26 layers with 26 QKV layers, 26 O layers and 26 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"vITh0KVJ10qX"},"source":["<a name=\"Data\"></a>\n","### Data Prep\n","We now use the Ecommerce Chatbot dataset on Roman Nepali Here.\n","\n","**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n","\n","**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise we'll get infinite generations!\n","\n","If weou want to use the `llama-3` template for ShareGPT datasets, try  conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n","\n","For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["275f39c24dde4c37a5a9b0dfb72fe9f3","e5abe5feadf84f7f810e17221a73b465","3400b2e8333d4ca7b0053d2a4dba9d86","a031cc49216044629a91ffe7435229df","15578571051d4bacaffa3a0c7bab7654","f24ff1dcdc6944ee850dc3ae8c8e9408","f5dea984964d4f13b1b18ebc9dbce4b2","3e928a516c484c5c90c648ce49e3adb8","8b1f1278e5484187aba72cdf44cba1d7","f9aae1bc8ca24886b4f9bf5f3d5972b4","338404fa5faf44098a601545d5641751"]},"executionInfo":{"elapsed":3410,"status":"ok","timestamp":1735142460999,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"LjY75GoYUCB8","outputId":"ae5175ef-d64a-41f7-be4b-174abe68807e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/33753 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"275f39c24dde4c37a5a9b0dfb72fe9f3"}},"metadata":{}}],"source":["alpaca_prompt = \"\"\"Answer the user question of ecommerce customer support in Roman Nepali Language.\n","\n","### Instruction:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"query\"]\n","    outputs      = examples[\"response\"]\n","    texts = []\n","    for instruction, output in zip(instructions, outputs):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"manojbaniya/ecommerce_qna\", split = \"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Train the model\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["85c2685bc0794a3bb1a1e2b75ae1e08b","c5ed6774e46e43d285fd468b982fadc9","6674ddf554184f9ca84d8c692d729df2","d36eb76dafa74bf4accad1b81ca9aae7","151e5dbc95ff479599fd853a2012ecf3","5cb51da4993143dda35a260f4253b63f","e40b8b75551e467baffcd20e728d8378","b1aa59894f9e4c0f91bba1f17b0bbf95","5d26e6766edb4cb59136076154dab077","b577af9f9d734a6aa6bef50d22afd101","305ba231aace4ce8bb307a7f41a382b5"]},"executionInfo":{"elapsed":11169,"status":"ok","timestamp":1735142516892,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"95_Nn-89DhsL","outputId":"3ea539aa-1579-484b-d3ba-ed7719aea6a1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/33753 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c2685bc0794a3bb1a1e2b75ae1e08b"}},"metadata":{}}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        # num_train_epochs = 1, # Set this for 1 full training run.\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","    ),\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1735142681082,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"2ejIt2xSNKKp","outputId":"241bad68-240f-4b27-d6e2-a1a5532cc2b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","3.576 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats no\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqxqAZ7KJ4oL","outputId":"3e8cf901-aba3-4d2b-e9a0-f468905ed70e","executionInfo":{"status":"ok","timestamp":1735142681082,"user_tz":-345,"elapsed":160093,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 33,753 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 20,766,720\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 01:54, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>5.493800</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>5.576900</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>5.295400</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>4.877000</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>4.385800</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>3.677400</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>3.473000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.935500</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.454400</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.357900</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.680400</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.382700</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.074300</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>2.145900</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.030500</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.166100</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.979400</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.593700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.932900</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.900100</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>2.171400</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.883900</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.917400</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.537900</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.468700</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.481600</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.928100</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>1.650100</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>1.637900</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.861500</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>1.550300</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>1.810700</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>1.461700</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>1.300500</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>1.537400</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>1.250800</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>1.011000</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>1.634500</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>1.605200</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.945400</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>1.634200</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>1.351600</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>1.497600</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>1.645100</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>1.370100</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>1.711300</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>1.344300</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>1.444400</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>1.331700</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.786100</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>1.444700</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>1.741500</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>1.422000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>1.328300</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>1.437000</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>1.416700</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>1.238500</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>1.435900</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>1.780500</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.303400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"pCqnaKmlO1U9","outputId":"dcb9b366-31c1-431a-cca7-1c13df6c237d","executionInfo":{"status":"ok","timestamp":1722441956792,"user_tz":420,"elapsed":14,"user":{"displayName":"Daniel Han-Chen","userId":"17402123517466114840"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["278.0636 seconds used for training.\n","4.63 minutes used for training.\n","Peak reserved memory = 7.684 GB.\n","Peak reserved memory for training = 4.987 GB.\n","Peak reserved memory % of max memory = 52.102 %.\n","Peak reserved memory for training % of max memory = 33.815 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","metadata":{"id":"ekOmTR1hSNcr"},"source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR3gIAX-SM2q","outputId":"331fddee-7439-4a84-8fbe-e62bf07e72af","executionInfo":{"status":"ok","timestamp":1735142780391,"user_tz":-345,"elapsed":15009,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<bos>Answer the user question of ecommerce customer support in Roman Nepali Language.\\n\\n### Instruction:\\nstore location kahaa xa\\n\\n### Response:\\nstore location ko lagi map bataa saknuhunchha.<eos>']"]},"metadata":{},"execution_count":9}],"source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"store location kahaa xa\", # instruction\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"]},{"cell_type":"markdown","metadata":{"id":"CrSvZObor0lY"},"source":[" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2pEuRb1r2Vg","outputId":"fc5710b4-bc34-4240-e3f2-2ada4d208308","executionInfo":{"status":"ok","timestamp":1735142827916,"user_tz":-345,"elapsed":2987,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user question of ecommerce customer support in Roman Nepali Language.\n","\n","### Instruction:\n","Account kholna ke ke lagcha?\n","\n","### Response:\n","Account kholna ko lagi, email address sahi chahincha.<eos>\n"]}],"source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Account kholna ke ke lagcha?\", # instruction\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Account kholne process ke ho?\", # instruction\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1pcHXk2kp2z","executionInfo":{"status":"ok","timestamp":1735142857842,"user_tz":-345,"elapsed":2887,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"54c90328-5115-4831-edb2-be876f30f8c3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user question of ecommerce customer support in Roman Nepali Language.\n","\n","### Instruction:\n","Account kholne process ke ho?\n","\n","### Response:\n","Account kholne process ko lagi, email address ko verification garna saknuhunchha.<eos>\n"]}]},{"cell_type":"code","source":["def generate_text(query):\n","    inputs = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            query, # instruction\n","            \"\", # output - leave this blank for generation!\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"2lIhsH74lWir","executionInfo":{"status":"ok","timestamp":1735143062420,"user_tz":-345,"elapsed":584,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["generate_text(\"ma kasari register garna sakchu?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCrY_xzHlgE0","executionInfo":{"status":"ok","timestamp":1735143086205,"user_tz":-345,"elapsed":1680,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"fbf2b488-47df-4b8f-c9c6-5b7a721e4968"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user question of ecommerce customer support in Roman Nepali Language.\n","\n","### Instruction:\n","ma kasari register garna sakchu?\n","\n","### Response:\n","ma kasari register garna sakchu.<eos>\n"]}]},{"cell_type":"code","source":["generate_text(\"profile delete garne option kaha cha?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dc0g55mLlsE1","executionInfo":{"status":"ok","timestamp":1735143213086,"user_tz":-345,"elapsed":2904,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7224e501-a6d9-4aed-a929-da81b312c019"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user question of ecommerce customer support in Roman Nepali Language.\n","\n","### Instruction:\n","profile delete garne option kaha cha?\n","\n","### Response:\n","profile delete garne option 'delete account' ma cha.<eos>\n"]}]},{"cell_type":"code","source":["generate_text(\"delivery option ke ke cha?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--LPmBz-mL3j","executionInfo":{"status":"ok","timestamp":1735143403193,"user_tz":-345,"elapsed":1313,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"33f41b0d-1c18-4e6e-ff85-44b7dbac20ae"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user question of ecommerce customer support in Roman Nepali Language.\n","\n","### Instruction:\n","delivery option ke ke cha?\n","\n","### Response:\n","delivery option ko lagi, free shipping available cha.<eos>\n"]}]},{"cell_type":"code","source":["generate_text(\"what is AI?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OoZSkSptm0Sr","executionInfo":{"status":"ok","timestamp":1735143418745,"user_tz":-345,"elapsed":2782,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"2842c7ba-9473-4c1f-e02c-45773726e11d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user question of ecommerce customer support in Roman Nepali Language.\n","\n","### Instruction:\n","what is AI?\n","\n","### Response:\n","AI is a technology that helps machines learn and make decisions like humans.<eos>\n"]}]},{"cell_type":"code","source":["def generate_text(query):\n","    prompt = \"Answer the user query about Ecommerce in Roman Nepali using context below and answer only what is needed ### Instruction {query} ### Context: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha. ### Response\"\n","    inputs = tokenizer(\n","    [\n","        prompt.format(\n","            query=query\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"HZFNhPHwm46k","executionInfo":{"status":"ok","timestamp":1735143952079,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["generate_text(query=\"Store ko naam ke ho?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQMwL8_rnFKY","executionInfo":{"status":"ok","timestamp":1735143960195,"user_tz":-345,"elapsed":6471,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ec49226c-b8b2-42f5-c9ac-c0e6ec082fce"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user query about Ecommerce in Roman Nepali using context below and answer only what is needed ### Instruction Store ko naam ke ho? ### Context: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha. ### Response: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha.<eos>\n"]}]},{"cell_type":"code","source":["generate_text(query=\"Store ma k paucha?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVEDaeVuogd6","executionInfo":{"status":"ok","timestamp":1735143968366,"user_tz":-345,"elapsed":3259,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e0b727f5-7107-4245-ea15-e3ddcb281968"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user query about Ecommerce in Roman Nepali using context below and answer only what is needed ### Instruction Store ma k paucha? ### Context: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha. ### Response: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha.<eos>\n"]}]},{"cell_type":"code","source":["def generate_text(query):\n","    prompt = \"\"\"\n","    You are Ecommerce AI Assistant and will only answer about ecommerce queries in only Roman Nepali Language and will use the data below:\n","\n","    ### Context\n","    Hamro store ko naam happy store ho\n","    hami sabi prakar ko books haru bechchau\n","    Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha.\n","    Rato Tshirt ko price 1000 ho\n","    Nilo Tshirt ko price 2000 ho\n","    Nike jutta ko paisa 3000 ho\n","\n","    ### Question\n","    {query}\n","\n","    ### Response\"\"\"\n","    inputs = tokenizer(\n","    [\n","        prompt.format(\n","            query=query\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"RcQXyrLQqGwD","executionInfo":{"status":"ok","timestamp":1735144450791,"user_tz":-345,"elapsed":581,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["generate_text(\"store ko name ke ho?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tW7DHQ-SqzMH","executionInfo":{"status":"ok","timestamp":1735144594606,"user_tz":-345,"elapsed":1560,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"bbc0e610-cfdb-4582-ab88-977a8543ad84"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","    You are Ecommerce AI Assistant and will only answer about ecommerce queries in only Roman Nepali Language and will use the data below:\n","\n","    ### Context\n","    Hamro store ko naam happy store ho\n","    hami sabi prakar ko books haru bechchau\n","    Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha.\n","    Rato Tshirt ko price 1000 ho\n","    Nilo Tshirt ko price 2000 ho\n","    Nike jutta ko paisa 3000 ho\n","\n","    ### Question\n","    store ko name ke ho?\n","\n","    ### Response\n","    store ko name happy store ho.<eos>\n"]}]},{"cell_type":"markdown","metadata":{"id":"uMuVrWbjAzhc"},"source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upcOlWe7A1vc","outputId":"84534cad-bca3-425d-90f1-d16c0295ae18","executionInfo":{"status":"ok","timestamp":1722441987784,"user_tz":420,"elapsed":1061,"user":{"displayName":"Daniel Han-Chen","userId":"17402123517466114840"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.model',\n"," 'lora_model/added_tokens.json',\n"," 'lora_model/tokenizer.json')"]},"metadata":{},"execution_count":11}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n","# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"]},{"cell_type":"markdown","metadata":{"id":"AEEcJ4qfC7Lp"},"source":["Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MKX_XKs_BNZR","outputId":"7b791800-16fb-4a7b-84ca-9c23c349b150","executionInfo":{"status":"ok","timestamp":1722441993895,"user_tz":420,"elapsed":6126,"user":{"displayName":"Daniel Han-Chen","userId":"17402123517466114840"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","What is a famous tall tower in Paris?\n","\n","### Input:\n","\n","\n","### Response:\n","The Eiffel Tower is a famous tall tower in Paris, France. It is located in the 5th arrondissement of Paris and is one of the most recognizable landmarks in the world. The tower was built for the 1889 World's Fair and is 324 meters tall. It is made of iron and has 1,665 steps. The tower is a symbol of Paris and is a popular tourist attraction.<eos>\n"]}],"source":["if False:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","# alpaca_prompt = You MUST copy from above!\n","\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"account banaune option ke ke ho?\", # instruction\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"]},{"cell_type":"markdown","metadata":{"id":"QQMjaNrjsU5_"},"source":["You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFfaXG0WsQuE"},"outputs":[],"source":["if False:\n","    # use Unsloth if possible\n","    from peft import AutoPeftModelForCausalLM\n","    from transformers import AutoTokenizer\n","    model = AutoPeftModelForCausalLM.from_pretrained(\n","        \"lora_model\", #  MODEL YOU USED FOR TRAINING\n","        load_in_4bit = load_in_4bit,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"]},{"cell_type":"markdown","metadata":{"id":"f422JgM9sdVT"},"source":["### Saving to float16 for VLLM\n","\n","We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHjt_SMYsd3P"},"outputs":[],"source":["# Merge to 16bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n","\n","# Merge to 4bit\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n","\n","# Just LoRA adapters\n","if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n","if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"]},{"cell_type":"markdown","metadata":{"id":"TCv4vXHd61i7"},"source":["### GGUF / llama.cpp Conversion\n","To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n","\n","Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n","* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n","* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n","* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n","\n","[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqfebeAdT073"},"outputs":[],"source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","# Remember to go to https://huggingface.co/settings/tokens for a token!\n","# And change hf to your username!\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n","\n","# Save to multiple GGUF options - much faster if you want multiple!\n","if False:\n","    model.push_to_hub_gguf(\n","        \"hf/model\", # Change hf to your username!\n","        tokenizer,\n","        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n","        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n","    )"]},{"cell_type":"markdown","metadata":{"id":"bDp0zNpwe6U_"},"source":["Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html).\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"markdown","metadata":{"id":"Zt9CHJqO6p30"},"source":["And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n","\n","Some other links:\n","1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n","2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n","3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n","4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n","5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n","6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with ðŸ¤— HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n","7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n","8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n","9. [**NEW**] We make Phi-3 Medium / Mini **2x faster**! See our [Phi-3 Medium notebook](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing)\n","10. [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","11. [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","12. [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)\n","13. [**NEW**] Llama 3.1 8b, 70b and 405b is here! We make it 2x faster and use 60% less VRAM. [Llama 3.1 8b notebook](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing)\n","\n","<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n","</div>"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1weTpKOjBZxZJ5PQ-Ql8i6ptAY2x-FWVA","timestamp":1735142027225},{"file_id":"1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp","timestamp":1722408149017},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1721714808667},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ad63e965f2154fecb67a15647a841477":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bafcc60b72e24c34afb6a1a19959ccee","IPY_MODEL_08e0441e5d2f443db4f0a48a81cc0838","IPY_MODEL_9d1be81c03e943a6ad24e5e1b9397424"],"layout":"IPY_MODEL_b2d5b1277b92456d833deb10824b992a"}},"bafcc60b72e24c34afb6a1a19959ccee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf202bd778924e70aeda28e16fa4ec4a","placeholder":"â€‹","style":"IPY_MODEL_e5444f22168942f9a54d4b47a85ab583","value":"model.safetensors:â€‡100%"}},"08e0441e5d2f443db4f0a48a81cc0838":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_905525b6561d4155a714f6b33697f7e7","max":2224765107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c187db8dee5e44a487f8b1bb5e20c3e6","value":2224764895}},"9d1be81c03e943a6ad24e5e1b9397424":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da8b59241d424192a9992980666481ee","placeholder":"â€‹","style":"IPY_MODEL_839cb8f5c7974a139e7627057d1a130e","value":"â€‡2.22G/2.22Gâ€‡[00:10&lt;00:00,â€‡324MB/s]"}},"b2d5b1277b92456d833deb10824b992a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf202bd778924e70aeda28e16fa4ec4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5444f22168942f9a54d4b47a85ab583":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"905525b6561d4155a714f6b33697f7e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c187db8dee5e44a487f8b1bb5e20c3e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da8b59241d424192a9992980666481ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"839cb8f5c7974a139e7627057d1a130e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90d1a138d924496990ff34388bb0dc47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_777ca5ac8e384fed87ae01694711981b","IPY_MODEL_1589ea0d7126417893c1e08bfc10a2ed","IPY_MODEL_71c9c71aa2ab4419b1f5b6e07d6b6012"],"layout":"IPY_MODEL_22a05c8895244b44b84ba530d5c12046"}},"777ca5ac8e384fed87ae01694711981b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36ee3488206f4861bccfb5a34a4e1210","placeholder":"â€‹","style":"IPY_MODEL_2f5bef8c9dca48ef90878782be2321a6","value":"generation_config.json:â€‡100%"}},"1589ea0d7126417893c1e08bfc10a2ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86bfc2d88ebc411abc173e050f07ccfa","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dab428459ce64f0e8c4f457c17ea92b6","value":190}},"71c9c71aa2ab4419b1f5b6e07d6b6012":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c88dfef5527942869312a014e7fcb459","placeholder":"â€‹","style":"IPY_MODEL_ebb9264d06fd4823970d5f780bbf0d83","value":"â€‡190/190â€‡[00:00&lt;00:00,â€‡12.9kB/s]"}},"22a05c8895244b44b84ba530d5c12046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36ee3488206f4861bccfb5a34a4e1210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f5bef8c9dca48ef90878782be2321a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86bfc2d88ebc411abc173e050f07ccfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dab428459ce64f0e8c4f457c17ea92b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c88dfef5527942869312a014e7fcb459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebb9264d06fd4823970d5f780bbf0d83":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"265a41094c0f43e98d300e826b26d6c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b4c36996f40468db0e66f51ce9090f6","IPY_MODEL_1910318f2d88454eb7b81fbddbc97bb3","IPY_MODEL_204c8ad45e754a03b85dd64023e81c4a"],"layout":"IPY_MODEL_c58272d80f224c30b5a03f183158bff9"}},"5b4c36996f40468db0e66f51ce9090f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd5719522d854735b9729c1c28b7ae77","placeholder":"â€‹","style":"IPY_MODEL_51cf83e6bc474db7970a6dd3a683b78f","value":"tokenizer_config.json:â€‡100%"}},"1910318f2d88454eb7b81fbddbc97bb3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_48e9d677229b4dbc91de94dc4c3ca967","max":46405,"min":0,"orientation":"horizontal","style":"IPY_MODEL_67176738d3a64f109d4184a99b5ad794","value":46405}},"204c8ad45e754a03b85dd64023e81c4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d04e8041384a402f8875b91d560a0793","placeholder":"â€‹","style":"IPY_MODEL_16841c3d1d9947a68cdcb218cf2515fa","value":"â€‡46.4k/46.4kâ€‡[00:00&lt;00:00,â€‡3.69MB/s]"}},"c58272d80f224c30b5a03f183158bff9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd5719522d854735b9729c1c28b7ae77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51cf83e6bc474db7970a6dd3a683b78f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48e9d677229b4dbc91de94dc4c3ca967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67176738d3a64f109d4184a99b5ad794":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d04e8041384a402f8875b91d560a0793":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16841c3d1d9947a68cdcb218cf2515fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"adcb10daa0f641baae1bd60dce22c06a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8508ba2db36646a5a7002fec07aaee52","IPY_MODEL_5aecf2fb3d2842ed8c340e6d0e2d581b","IPY_MODEL_8935500a52ec4389961113f79be6bf33"],"layout":"IPY_MODEL_f26bf59b11d04016a98b9b481e04a69e"}},"8508ba2db36646a5a7002fec07aaee52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2855683718f4501be28ca640378a41d","placeholder":"â€‹","style":"IPY_MODEL_6175601dfa7e441f851ff3efdcf8c8d6","value":"tokenizer.model:â€‡100%"}},"5aecf2fb3d2842ed8c340e6d0e2d581b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b5fb1a5b54f41b4ac79ba264fda87fa","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4c1d8be6b984dffa9de1887b74fd539","value":4241003}},"8935500a52ec4389961113f79be6bf33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f372a3fddf9243dfae57b64beea0053c","placeholder":"â€‹","style":"IPY_MODEL_d6441cbf010a4ff1a38e12bf200215ba","value":"â€‡4.24M/4.24Mâ€‡[00:00&lt;00:00,â€‡40.5MB/s]"}},"f26bf59b11d04016a98b9b481e04a69e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2855683718f4501be28ca640378a41d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6175601dfa7e441f851ff3efdcf8c8d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b5fb1a5b54f41b4ac79ba264fda87fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4c1d8be6b984dffa9de1887b74fd539":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f372a3fddf9243dfae57b64beea0053c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6441cbf010a4ff1a38e12bf200215ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28ab66a19dfa41c4af2aeb7328ef4b87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6742a31daed4f0bb4bdad685174b751","IPY_MODEL_d4034e0067e847ac9789d8a009ec90bd","IPY_MODEL_af55ff1d963d49f38ffdd870c0f0f171"],"layout":"IPY_MODEL_a596829c63f4427f96864851b8b325e5"}},"f6742a31daed4f0bb4bdad685174b751":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e10d59cb05b4a988570a42655235782","placeholder":"â€‹","style":"IPY_MODEL_cad79e0205a74378b75d5624653d0c3a","value":"special_tokens_map.json:â€‡100%"}},"d4034e0067e847ac9789d8a009ec90bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07d9a41595c34e619f3154783432a6fb","max":636,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56d0eb658166466cbe5601cebb9b987a","value":636}},"af55ff1d963d49f38ffdd870c0f0f171":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3148bbbc46cc4c5b84497a2e0d83d783","placeholder":"â€‹","style":"IPY_MODEL_9ec0f07db1b841ad994a96a2148b000a","value":"â€‡636/636â€‡[00:00&lt;00:00,â€‡26.7kB/s]"}},"a596829c63f4427f96864851b8b325e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e10d59cb05b4a988570a42655235782":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad79e0205a74378b75d5624653d0c3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07d9a41595c34e619f3154783432a6fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56d0eb658166466cbe5601cebb9b987a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3148bbbc46cc4c5b84497a2e0d83d783":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ec0f07db1b841ad994a96a2148b000a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ee1f440dcce41acbc9848a1643c2cf7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbbd9836d26e45459002349733936536","IPY_MODEL_74eac32a118b49a995396ff0afb39019","IPY_MODEL_1ad01c134f9849578c51612b1e4bfedd"],"layout":"IPY_MODEL_ed225c34732748dda669f58e83d5247c"}},"fbbd9836d26e45459002349733936536":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc85c2b4200941bcbee84700fa3c6b9c","placeholder":"â€‹","style":"IPY_MODEL_4b69fcde9d884cb6851c2250f19440b0","value":"tokenizer.json:â€‡100%"}},"74eac32a118b49a995396ff0afb39019":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e34c45f73226425b80c796e6a946d200","max":17525357,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fc58f79e32d4f869a6175b09856dcbc","value":17525357}},"1ad01c134f9849578c51612b1e4bfedd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8eabcdbc67794dfb9f6a354ab2d15e20","placeholder":"â€‹","style":"IPY_MODEL_867f2304fd9d40e09308625298572833","value":"â€‡17.5M/17.5Mâ€‡[00:00&lt;00:00,â€‡42.3MB/s]"}},"ed225c34732748dda669f58e83d5247c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc85c2b4200941bcbee84700fa3c6b9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b69fcde9d884cb6851c2250f19440b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e34c45f73226425b80c796e6a946d200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc58f79e32d4f869a6175b09856dcbc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8eabcdbc67794dfb9f6a354ab2d15e20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"867f2304fd9d40e09308625298572833":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"275f39c24dde4c37a5a9b0dfb72fe9f3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5abe5feadf84f7f810e17221a73b465","IPY_MODEL_3400b2e8333d4ca7b0053d2a4dba9d86","IPY_MODEL_a031cc49216044629a91ffe7435229df"],"layout":"IPY_MODEL_15578571051d4bacaffa3a0c7bab7654"}},"e5abe5feadf84f7f810e17221a73b465":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f24ff1dcdc6944ee850dc3ae8c8e9408","placeholder":"â€‹","style":"IPY_MODEL_f5dea984964d4f13b1b18ebc9dbce4b2","value":"Map:â€‡100%"}},"3400b2e8333d4ca7b0053d2a4dba9d86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e928a516c484c5c90c648ce49e3adb8","max":33753,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b1f1278e5484187aba72cdf44cba1d7","value":33753}},"a031cc49216044629a91ffe7435229df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9aae1bc8ca24886b4f9bf5f3d5972b4","placeholder":"â€‹","style":"IPY_MODEL_338404fa5faf44098a601545d5641751","value":"â€‡33753/33753â€‡[00:00&lt;00:00,â€‡71266.97â€‡examples/s]"}},"15578571051d4bacaffa3a0c7bab7654":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f24ff1dcdc6944ee850dc3ae8c8e9408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5dea984964d4f13b1b18ebc9dbce4b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e928a516c484c5c90c648ce49e3adb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b1f1278e5484187aba72cdf44cba1d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9aae1bc8ca24886b4f9bf5f3d5972b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"338404fa5faf44098a601545d5641751":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85c2685bc0794a3bb1a1e2b75ae1e08b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5ed6774e46e43d285fd468b982fadc9","IPY_MODEL_6674ddf554184f9ca84d8c692d729df2","IPY_MODEL_d36eb76dafa74bf4accad1b81ca9aae7"],"layout":"IPY_MODEL_151e5dbc95ff479599fd853a2012ecf3"}},"c5ed6774e46e43d285fd468b982fadc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cb51da4993143dda35a260f4253b63f","placeholder":"â€‹","style":"IPY_MODEL_e40b8b75551e467baffcd20e728d8378","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"6674ddf554184f9ca84d8c692d729df2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1aa59894f9e4c0f91bba1f17b0bbf95","max":33753,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d26e6766edb4cb59136076154dab077","value":33753}},"d36eb76dafa74bf4accad1b81ca9aae7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b577af9f9d734a6aa6bef50d22afd101","placeholder":"â€‹","style":"IPY_MODEL_305ba231aace4ce8bb307a7f41a382b5","value":"â€‡33753/33753â€‡[00:10&lt;00:00,â€‡9954.56â€‡examples/s]"}},"151e5dbc95ff479599fd853a2012ecf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cb51da4993143dda35a260f4253b63f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e40b8b75551e467baffcd20e728d8378":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1aa59894f9e4c0f91bba1f17b0bbf95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d26e6766edb4cb59136076154dab077":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b577af9f9d734a6aa6bef50d22afd101":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"305ba231aace4ce8bb307a7f41a382b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}