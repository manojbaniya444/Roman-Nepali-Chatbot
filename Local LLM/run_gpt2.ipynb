{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LLM Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", cache_dir=\"./model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\", cache_dir=\"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The sky is falling. I was standing in front of the door when two men in glasses yelled at me to open it. Then they left, so I opened the door and they disappeared again, just to see you guys walking along for the ride home, yeah. We couldn't even make out your real faces or any parts of your bodies. They told me a story of how a white guy and a girl ran across our back and told me that they couldn't get back. I'm really glad\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation(\"The sky is\")[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I love my parents because I\\'m so blessed to have a family of my own making it possible to do what I do and I\\'m incredibly thankful to anyone who supported me.\\n\\n\"I don\\'t want to pretend I\\'m not being honest with'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation(\"I love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\"Hello there what are you doing\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612,   644,   389,   345,  1804]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,   612,   644,   389,   345,  1804,   994,  1701,   366,    32,\n",
       "           732,   345,   466,   553,   314,  8712,    11,   366,  4360,   356,\n",
       "           389,   477,   994,   284,   423,  1257,    13,  3914,   514,   466,\n",
       "           340,   355,   881,   355,  1744,    13,  3914,   338,   655,   467,\n",
       "           284,   262, 17374,   290,  2822,   617,  1243,   526,   198,   198]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there what are you doing here?\" \"Awe you do,\" I replied, \"but we are all here to have fun. Let us do it as much as possible. Let\\'s just go to the mall and buy some things.\"\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 464, 6766,  318, 4171]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"The sky is blue\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(tokenizer.encode(\"The sky is\", return_tensors=\"pt\"), max_length=20).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(max_length=1, seed_text=\"\"):\n",
    "    encoded = tokenizer(seed_text, return_tensors=\"pt\")\n",
    "    attention_mask = encoded[\"attention_mask\"]\n",
    "    pad_token_id = tokenizer.eos_token_id\n",
    "    max_length += encoded[\"input_ids\"].shape[1]\n",
    "    \n",
    "    outputs = model.generate(encoded[\"input_ids\"], attention_mask=attention_mask, pad_token_id=pad_token_id, max_length=max_length)\n",
    "    response = tokenizer.decode(outputs[0])\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is the limit.\"\n",
      "\n",
      "The wind's force\n",
      "\n",
      "Even if a man like Kukkou didn't think about moving up or down, the wind's force could not be compared to that of a wind. This wind's power was comparable to the distance travelled by an aircraft.\n",
      "\n",
      "The wind was only at its strongest.\n",
      "\n",
      "Although this wind was extremely strong, it could not rival the strength of a plane.\n",
      "\n",
      "Only even after all these years, it would have already been\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(seed_text=\"The sky is\", max_length=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"I am sure that\"\n",
    "encoded = tokenizer(question, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sure that all of the other characters would benefit from more detailed depictions of their actions.\"\n",
      "\n",
      "The Star Wars prequels did not have a scene where Han Solo and Chewbacca were having sex.\n",
      "\n",
      "Star Wars: The Force Awakens has seen a host of sex scenes and other scenes where characters in the films have sex.\n",
      "\n",
      "Star Wars: Episode VII - A New Hope was set to star Kylo Ren in the film, which was also directed by J.J.\n"
     ]
    }
   ],
   "source": [
    "streamer = TextStreamer(tokenizer, skip_prompt=False)\n",
    "outputs = model.generate(**encoded,\n",
    "                   streamer=streamer,\n",
    "                   pad_token_id=tokenizer.eos_token_id,\n",
    "                   max_length=100,\n",
    "                   top_p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40,   716,  1654,   326,   477,   286,   262,   584,  3435,   561,\n",
       "          4414,   422,   517,  6496, 44528,   286,   511,  4028,   526,   198,\n",
       "           198,   464,  2907,  6176,   662,   421,  1424,   750,   407,   423,\n",
       "           257,  3715,   810,  9530, 20284,   290,  2580, 39346, 43552,   547,\n",
       "          1719,  1714,    13,   198,   198,  8248,  6176,    25,   383,  5221,\n",
       "         39613,   468,  1775,   257,  2583,   286,  1714,  8188,   290,   584,\n",
       "          8188,   810,  3435,   287,   262,  7328,   423,  1714,    13,   198,\n",
       "           198,  8248,  6176,    25,  7922, 19691,   532,   317,   968, 13408,\n",
       "           373,   900,   284,  3491, 39859,    78,  7152,   287,   262,  2646,\n",
       "            11,   543,   373,   635,  7924,   416,   449,    13,    41,    13]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextIteratorStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([\"The sky is.\"], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextIteratorStreamer(tokenizer, skip_prompt=False)\n",
    "generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=100)\n",
    "\n",
    "thread = Thread(target=model.generate, kwargs=generation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is.\n",
      "\n",
      "You can't see things from that space but the sky is a place so we're going to start looking a little deeper into it. We have a lot of new technology and exciting things ahead of us and this is just more of an engineering question…\n",
      "\n",
      "NARRATOR: Dr. Ettorr said, \"We've just identified a new form of particle physics, called the super-physics' of particles which are actually quantum waves. That's exactly what we are"
     ]
    }
   ],
   "source": [
    "thread.start()\n",
    "for new_text in streamer:\n",
    "    print(new_text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "\n",
    "def get_stream_response(input_text=\"\", max_length=100):\n",
    "    streamer = TextIteratorStreamer(tokenizer, skip_prompt=False)\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=max_length)\n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "    for new_text in streamer:\n",
    "        print(new_text, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is red. I have heard that there are other beings like me alive.\" ―Alyeanna [src]\n",
      "\n",
      "Alyeanna was named after a mother, a daughter and wife who she married to her lover, Alysanna, later on to a girl named Amida who was her child's name[9] and whom she taught to her daughter, Alysanna Alysanna, at age 17[10]. Alyeanna was not only Alysanna's step-mother"
     ]
    }
   ],
   "source": [
    "get_stream_response(\"The sky is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who are you?) or who are your own parents.\n",
      "\n",
      "In the first few seconds of pregnancy, the mother doesn't think she's got everything. \"Oh, no, it's okay,\" she says. \"It's just that I'm scared.\"\n",
      "\n",
      "Some moms don't get a chance to get back in touch. Some are unable to cope with daily physical activity. Some try to prevent or even prevent pregnancy and make the worst decision that they can. There are, of course, women who need to take extra time to get through an emotional pregnancy.\n",
      "\n",
      "So don't be intimidated, even by people who care about your wellbeing and are willing to pay for such attention. They may be more likely to respond with a desire to have it done than the people you ask but don't always know how they can make that happen. You should seek help right now if you have to get involved.\n",
      "\n",
      "If you want to get to grips with a healthy pregnancy, look no further than this week's Women.com survey. It offers answers (and you might be interested in participating at the event) about women looking to get pregnant with their first child.\n",
      "\n",
      "We spoke to 1,074 pregnant women — all of whom gave us excellent insight into their own mental health. We can't wait to share it with you. The survey is open to non-whites, but it's also relevant to a wide range of women:\n",
      "\n",
      "The survey questions were collected using the Nolo Survey System, which is used for self-identifying and reporting, and includes a wealth of personalised responses.\n",
      "\n",
      "The final survey was conducted online by a private group with 100 women. They had the opportunity to complete an online questionnaire and a private part of their online health survey. We've also provided a link to the questionnaire to give you a visual guide on how to fill it out.\n",
      "\n",
      "Read the end of this post on how you can make the best decision if you ask it, and the survey here.\n",
      "\n",
      "What do you think about this survey? Can you share? Comment below.\n",
      "\n",
      "[Image via Shutterstock]\n",
      "\n",
      "Have what you see in this post changed your life? What else can you share about pregnancy?<|endoftext|>"
     ]
    }
   ],
   "source": [
    "get_stream_response(\"who are you\", 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
