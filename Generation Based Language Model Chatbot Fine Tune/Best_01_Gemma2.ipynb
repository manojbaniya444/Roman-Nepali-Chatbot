{"cells":[{"cell_type":"markdown","source":["## Fine Tune Gemma2 2b quantized model on Ecommerce Question Answer"],"metadata":{"id":"Tb4mHTwDpFon"}},{"cell_type":"markdown","metadata":{"id":"IqM-T1RTzY6C"},"source":["To install Unsloth on own computer,the installation instructions Github page [here](https://github.com/unslothai/unsloth#installation-instructions---conda).\n","\n"," [data prep](#Data), [train](#Train),  [run the model](#Inference), & [how to save it](#Save) (eg for Llama.cpp).\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1736962748309,"user_tz":-345,"elapsed":50856,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[],"source":["%%capture\n","!pip install unsloth\n","# Also get the latest nightly Unsloth!\n","!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n","\n","# Install Flash Attention 2 for softcapping support\n","import torch\n","if torch.cuda.get_device_capability()[0] >= 8:\n","    !pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""]},{"cell_type":"markdown","metadata":{"id":"r2v_X2fA0Df5"},"source":["* We support Llama, Mistral, Phi-3, Gemma, Yi, DeepSeek, Qwen, TinyLlama, Vicuna, Open Hermes etc\n","* We support 16bit LoRA or 4bit QLoRA. Both 2x faster.\n","* `max_seq_length` can be set to anything, since we do automatic RoPE Scaling via [kaiokendev's](https://kaiokendev.github.io/til) method.\n","* [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","* [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","* [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353,"referenced_widgets":["bdca1aa73bc4400584d4e7168ca004db","814594086b7b4ad48745231c521c5e90","ed0a2ff57a714ca49d1b1ec48d739a19","ad3424ffa68947aa89f248d4d0f97411","09b96432674d4f329c6c897920aeb16c","b5222e518a3f4dc89e42b724b53ca88d","0e936eb4eea64be592617c98f8e96851","25875d2596f74e8893a43d0d11552410","9da03c197bf84a23abeed3429bf04f89","3a256b11a6e9411580bbb2882c58754e","61b1ac7d56d54ab6a8ef0be22b29cb70","4f8e5554aef54f6a90c3e39c3a1edc17","2d35b2c3c1e14b18b816b9db642f9869","ef76eca2c8f3436fad8c10a886fca427","a4dba1651bd74f0e8b2aaa1d75a4aec1","039f71eb05d549e39e42be87e413a955","b966e181a56d4da19acb8b3ac9368cb5","d14ba115edf94a2a9353c9d42527e525","c5e00e7aa64546b1892da5cd88af354d","02d21da0b2b14e77a61f176883679886","8b2a1ee94ce5429387b269b0271fa0dd","5a4ac7a8d63b47ecb14fdc0301dcd33e","6c590fe844a24df1a308cc1056c5ca55","deed436887344b309ba1629e433aa40d","3892a56788f44a95bc681941e13ba646","bcfd7215687d4642a0aba0e5879adb3b","79f210cf976a42fba4c460d3e3d80e3e","8a7540a5b3424cff8e492b0cc7c38de6","e152291fdb5d41e88b1d132e6aabc761","160ae4f1188c46e7a3ff3b773aaae0cb","74d236fe6479441798823f95ed1d15fd","171ae18d529444ce8dc050add2767d83","a37e9f2e2ec745c985ab981bb08876bd","7f91b18b22924cc680f5a5cf45a9dd7d","8bf36d8b984343f1929ed11eb78492ee","d61154e2351f400eb7a395ec9c67fc46","4279438872da4edfb5696ef29d7b872c","65b406bf959d4f35848149491871582c","58be43afdfb54cfc8e6e5b0a141ccd76","bf0672e39dd543b2847c425ed1b3b708","7f7baf39a1af43eca6be4688784ae26f","966f0ab0ef634fe0b4daa3afcbcf4a52","dc49e94519e3487a9f5a7f563892bde0","90cdeacb2a764b938d10d3ca55041f06","ee8e6469e4d2462a8d4f3b46f11bc540","6019c070f6954d4cb3e4a4b546383d81","aba9fffcb5ae4149b2ba66789a910fa0","8144d03b54b34b7590f7004424e46a20","1eee4d66be3a471292c26b75b2ba4a08","b36574a521b441f6ba86e7e89d96db06","7a55b3825c9c4966948ce56a2a33ea62","b680479850394d0a880b3e3085cdb700","eeee459d8a95404e8b5bcbb62bfbe72a","a2c3fc8ddafe40eb85fea53c4f531ac2","60dbe0b4dccf4bbc9b953111d05901ac","d6d3de692ada4bdb9454d6e897f2594d","c3c7f30612a9416f837ad44a88f50ffc","70413fb43336433394e17763ba9d9b23","fdae07c349ac49538794785e3d87ec74","4e79626e1f0c4782a80d0182b046d35b","0fdb674fe63d45b58a5957df3207a23d","036cfd6a70164417b0fd1856208ffa25","14374b1e22d34b709d6092e63f031483","2fb464313a514350929ef2279731d36a","6ab5a7f837dc4f35b13e646a7d0b1b9f","28ba55ada38c453f86172847178ce36b"]},"executionInfo":{"elapsed":87889,"status":"ok","timestamp":1736962836191,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"QmUBVEnvCDJv","outputId":"fba61d9a-4818-4a40-d1a7-0365b859cd74"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","==((====))==  Unsloth 2025.1.5: Fast Gemma2 patching. Transformers: 4.47.1.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.22G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdca1aa73bc4400584d4e7168ca004db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f8e5554aef54f6a90c3e39c3a1edc17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c590fe844a24df1a308cc1056c5ca55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f91b18b22924cc680f5a5cf45a9dd7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee8e6469e4d2462a8d4f3b46f11bc540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d3de692ada4bdb9454d6e897f2594d"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","    \"unsloth/gemma-2-2b-bnb-4bit\",             # New small Gemma model!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/gemma-2-2b\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9559,"status":"ok","timestamp":1736962845739,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"6bZsfBuZDeCL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"555a05dc-0b54-4c43-ea4b-055b7ad2df47"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2025.1.5 patched 26 layers with 26 QKV layers, 26 O layers and 26 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"vITh0KVJ10qX"},"source":["<a name=\"Data\"></a>\n","### Data Prep\n","We now use the Ecommerce Chatbot dataset on Roman Nepali Here.\n","\n","**[NOTE]** To train only on completions (ignoring the user's input) read TRL's docs [here](https://huggingface.co/docs/trl/sft_trainer#train-on-completions-only).\n","\n","**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise we'll get infinite generations!\n","\n","If weou want to use the `llama-3` template for ShareGPT datasets, try  conversational [notebook](https://colab.research.google.com/drive/1XamvWYinY6FOSX9GLvnqSjjsNflxdhNc?usp=sharing).\n","\n","For text completions like novel writing, try this [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)."]},{"cell_type":"code","source":["from datasets import load_dataset\n","dataset = load_dataset(\"manojbaniya/ift\", split = \"train\")\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":185,"referenced_widgets":["2e3ccdd4074b40129f09d7d4eec7cc18","cb2f5d85f4d042999b5f46ddedc268dc","eb2a06b94d0748baa98bc468d0306629","d180a15e04544b8497001bf0dedc4d29","6915cacc8ad54521a704beb3295d5638","8fd6e005b47143b9b1b4db4d0d1b6c87","7f8bf8b39b004f4d8ba8d16527d26a86","7f4d32c6a4f94c7e99c67fd62aac41ab","9d97d4f8dd804b21b3a3c3af7fc20ec2","02d32f7ec362404fb9c4ca00514a121a","f57f45a0f48e41968e57fb4a979d6d00","4228ed08916f44978c11cea1af67b776","ba228c5c260c499db041e8e6edd91786","ba6bde9ba5ab4ec6aa9ae6c5d5af6d92","41282503bf4c462ea2e83d955d6e64f0","a3d7c0e904ea4897aef189ea4815e69d","0ac900f513e449c296393c6015f64436","427e9b62a3bd46f5b4404512a04817ed","eb18644670904129aa9e8a0124f39c9b","026d2927018c45b3bc4a4c7c943fd834","8a3da1730c1f47e28a854ba16f601e60","8a84932ca13b434e9171abf124b8dcfb","2c99655d41d14ac2a042c3c0deb08fea","acc24cbb8ca74021881c6de4e9a35c03","3d4eb387cd374eb2bce2b67aca0b7018","52076e0e1cef4e68b38348d77a4c91b2","474e31a43dce4350adc07e638928fea1","4cd042ebb472411a8b9d696339dee2ef","1992ae052e3a4d11af194461cfa471e8","6942408aa89f4a35bfef40db33f1b2f3","d3a6f870e19e4534a201ab2af415bcd6","1a20b3727ee04f9680c7dc0c4554eff2","e1e65d8bbe3543d5a5958db85a0716a9"]},"id":"TiQuCLr1pDHj","executionInfo":{"status":"ok","timestamp":1736962848040,"user_tz":-345,"elapsed":2312,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"41a45b2f-dd55-4ea2-dabe-02cd20335bd0"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/193 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e3ccdd4074b40129f09d7d4eec7cc18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["shuffled.csv:   0%|          | 0.00/1.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4228ed08916f44978c11cea1af67b776"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c99655d41d14ac2a042c3c0deb08fea"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Unnamed: 0', 'category', 'system', 'instruction', 'context', 'question', 'response'],\n","    num_rows: 4768\n","})"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7oaO1akEpQE-","executionInfo":{"status":"ok","timestamp":1736962848040,"user_tz":-345,"elapsed":12,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ed6d6bb6-8e5f-4130-838b-2bfbb236d984"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['Unnamed: 0', 'category', 'system', 'instruction', 'context', 'question', 'response'],\n","    num_rows: 4768\n","})"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["dataset[100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kI9TFtjVqQJ3","executionInfo":{"status":"ok","timestamp":1736962903797,"user_tz":-345,"elapsed":432,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"2a3ab54a-8098-46a4-8efc-0f45c09226e8"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'Unnamed: 0': 100,\n"," 'category': 'RAG',\n"," 'system': 'Talako instruction herera user le gareko question ko Roman Nepali Language ma answer vana\\n\\n',\n"," 'instruction': 'User le gareko question lai, context herera mildo answer deu',\n"," 'context': 'Nepal ko ek prasiddha sthal Swayambhunath ho, jo Kathmandu ma sthit cha. Swayambhunath, jo monkeys temple ko rup ma pani janincha, ek dharmik aur sanskritik sthal ho. Swayambhunath le Nepal ko buddhist dharm ko gyan aur prashikshan ko pradarshan garincha.',\n"," 'question': 'Nepal ko ek prasiddha sthal k ho?',\n"," 'response': 'Swayambhunath, Nepal ko ek prasiddha sthal ho, jo Kathmandu ma sthit cha aur buddhist dharm ko gyan ko pradarshan garincha.'}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["dataset[\"instruction\"][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"p86NC2RFE94h","executionInfo":{"status":"ok","timestamp":1736963273627,"user_tz":-345,"elapsed":413,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"dd02c741-f3be-4ed3-c81c-0f19e20a770f"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'User le gareko question lai, answer deu.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":535,"status":"ok","timestamp":1736963342575,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"LjY75GoYUCB8"},"outputs":[],"source":["alpaca_prompt = \"\"\"\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","{instruction}\n","\n","### question:\n","{question}\n","\n","### input:\n","{context}\n","\n","### response:\n","{response}\n","\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    questions = examples[\"question\"]\n","    contexts = examples[\"context\"]\n","    responses = examples[\"response\"]\n","    texts = []\n","    for instruction, question, context, response in zip(instructions, questions, contexts, responses):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = alpaca_prompt.format(instruction=instruction, question=question, context=context, response=response) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }"]},{"cell_type":"code","source":["dataset = dataset.map(formatting_prompts_func, batched = True,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["58bfe71b94cc4c29b7b40f679973634a","d7a7c7783ccd40419ebc6ce16b68f438","da92b9aca9dd4a7b9dc219b57e3b03ab","6ec33091dfd245f7b132161fff4dea7f","b5bc3c3fab1e4de18fa6267aa6b4712c","cb88e667835c4216a2dd1786d3e3a26e","3904d3ada66144cd9015e30467cbcb8b","3e9b4adb9148409e8e72ac1310eacb77","65bc4f5b982f4cf2966d9f0ba5daf038","89d6f4f5a133431abdcd7c8c8eb5112e","2378d7be443a4a10803c2439235b02e6"]},"id":"8PWy2QNJpJew","executionInfo":{"status":"ok","timestamp":1736963345945,"user_tz":-345,"elapsed":419,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"398c92d4-5382-42c4-826b-58555e61dc8a"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4768 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58bfe71b94cc4c29b7b40f679973634a"}},"metadata":{}}]},{"cell_type":"code","source":["print(dataset[\"text\"][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYh4XwPmrkiU","executionInfo":{"status":"ok","timestamp":1736963347497,"user_tz":-345,"elapsed":431,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"e6dd4354-66c0-46f6-d50d-4a481fed27bc"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu.\n","\n","### question:\n","Nepali balbalika ko manobal kasari badhaune?\n","\n","### input:\n","None\n","\n","### response:\n","Balbalika lai utsah dina, uniharuko samasya sunnu, ra uniharuko safalta ko prashansa garnu parcha.\n","<eos>\n"]}]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Train the model\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["961e49cc0ee94712a1da4f4ce4fa8f67","46b8a9c11d1d4bc6ae605aa8e46eef5b","2c08f581fd6741029df0ba83db042fdf","56ed9b074f3f4a3182aa1e55cc1b6789","4c53eb50f1104a09b6893b24a030997d","69f7b062e10346bfbb17c29c122e242b","c400ee86d06943c7884ee39b5ad879ea","444c1516d43e4101b52e9ca9f7533a4a","0b75b69007bf4f6eae903c1756dbddc7","a737b6d75d0e4be6b22c5b39f7c67cdf","a6f719f0b6a84842a98b9e35f678e0f8"]},"executionInfo":{"elapsed":7301,"status":"ok","timestamp":1736963357343,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"95_Nn-89DhsL","outputId":"53dfaa3e-763f-4a5c-8a7f-6c93d543488e"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/4768 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"961e49cc0ee94712a1da4f4ce4fa8f67"}},"metadata":{}}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        # num_train_epochs = 1, # Set this for 1 full training run.\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        report_to = \"none\", # Use this for WandB etc\n","    ),\n",")"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1736963357343,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"},"user_tz":-345},"id":"2ejIt2xSNKKp","outputId":"19381b2d-88c4-4bb6-deb7-78e72a5ca37b"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","2.697 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats no\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqxqAZ7KJ4oL","outputId":"255aed89-bcf8-46c7-b0c8-935223bdd63d","executionInfo":{"status":"ok","timestamp":1736963527487,"user_tz":-345,"elapsed":170148,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 4,768 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 20,766,720\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 02:09, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>4.064500</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>4.390100</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>4.130100</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>3.635600</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>3.617500</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>3.452400</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.824500</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.605500</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.141200</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.170000</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.892300</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.970100</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.572500</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.677800</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.879300</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.297600</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.313400</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.640400</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.644300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.523900</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.149100</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.003400</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.336800</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.268400</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.537300</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.427400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.318000</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>1.490600</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>1.668000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.124300</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>1.278600</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>1.745800</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>1.208300</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>1.274800</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>1.374900</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>1.420000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>1.541500</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>1.305700</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>1.613700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.202400</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>1.248400</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>1.320100</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>1.198300</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>1.475100</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>1.348900</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>1.195000</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>1.323100</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>1.640300</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>1.584300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.369400</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>1.298500</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>1.569700</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>1.377000</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>1.095000</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>1.380300</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>1.271100</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>1.496100</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>1.074000</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>1.467300</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.364400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCqnaKmlO1U9","outputId":"9191b007-9bbf-4672-81de-ecc0e509aae2","executionInfo":{"status":"ok","timestamp":1736963541504,"user_tz":-345,"elapsed":1087,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["165.8835 seconds used for training.\n","2.76 minutes used for training.\n","Peak reserved memory = 4.891 GB.\n","Peak reserved memory for training = 2.194 GB.\n","Peak reserved memory % of max memory = 33.164 %.\n","Peak reserved memory for training % of max memory = 14.877 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","metadata":{"id":"ekOmTR1hSNcr"},"source":["<a name=\"Inference\"></a>\n","### Inference\n","Let's run the model! You can change the instruction and input - leave the output blank!\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR3gIAX-SM2q","outputId":"76055a9d-48ca-4b9c-a712-7b9dad7638cd","executionInfo":{"status":"ok","timestamp":1736963629829,"user_tz":-345,"elapsed":15306,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","what is the price of Samsung\n","\n","### input:\n","Redmi ko price 1000 ho Samsung ko 2000 ra Apple ko IPhone ko chai 200000 ho\n","\n","### response:\n","\n","Samsung ko price 2000 ho.\n","<eos>\n"]}],"source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"what is the price of Samsung\", # question\n","        context=\"Redmi ko price 1000 ho Samsung ko 2000 ra Apple ko IPhone ko chai 200000 ho\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"]},{"cell_type":"code","source":["print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Q7b0eBPtbYr","executionInfo":{"status":"ok","timestamp":1736963676485,"user_tz":-345,"elapsed":425,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"89104853-3a96-44c3-ad67-2d4ae4a74bf9"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","what is the price of Samsung\n","\n","### input:\n","Redmi ko price 1000 ho Samsung ko 2000 ra Apple ko IPhone ko chai 200000 ho\n","\n","### response:\n","\n","Samsung ko price 2000 ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Talako instruction herera user le gareko question ko Roman Nepali Language ma answer vana\",\n","        question=\"nepali ko main udhyog ke ho\",\n","        context=\"Nepal ko pramukh udhyog krishi, paryatan, ra silk manufacturing ho. Krishi ma sabai bhanda dherai udhyog chalne, ra paryatan ko sector ko vikas bhari chha.\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Mh7xmlz8PG_","executionInfo":{"status":"ok","timestamp":1736963697420,"user_tz":-345,"elapsed":3982,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"3a4b11e4-6373-4507-8ed7-98cc487b8d7e"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Talako instruction herera user le gareko question ko Roman Nepali Language ma answer vana\n","\n","### question:\n","nepali ko main udhyog ke ho\n","\n","### input:\n","Nepal ko pramukh udhyog krishi, paryatan, ra silk manufacturing ho. Krishi ma sabai bhanda dherai udhyog chalne, ra paryatan ko sector ko vikas bhari chha.\n","\n","### response:\n","\n","Krishi, paryatan, ra silk manufacturing Nepal ko pramukh udhyog ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"store ko location kahaa xa\",\n","        context=\"Hamro store ko name All Electronics Store ho ra hami sabai prakar ko electronics saman bechhanu. Tapaile esewa, khalti bata pay garna saknu hunxa hamro location Dharan ho\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pp-GImcBvMgo","executionInfo":{"status":"ok","timestamp":1736963725958,"user_tz":-345,"elapsed":2420,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"702c77aa-f003-4812-9a8f-e554069bf640"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","store ko location kahaa xa\n","\n","### input:\n","Hamro store ko name All Electronics Store ho ra hami sabai prakar ko electronics saman bechhanu. Tapaile esewa, khalti bata pay garna saknu hunxa hamro location Dharan ho\n","\n","### response:\n","\n","All Electronics Store, Dharan ma sabai prakar ko electronics saman bechhanu.\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"what is the price of Samsung\", # question\n","        context=\"Redmi ko price 1000 ho Samsung ko 2000 ra Apple ko IPhone ko chai 200000 ho\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlraKCJ1Gs4l","executionInfo":{"status":"ok","timestamp":1736963743253,"user_tz":-345,"elapsed":1517,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"bb7a1a97-6f8b-4854-faae-a7ebd7b8b300"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","what is the price of Samsung\n","\n","### input:\n","Redmi ko price 1000 ho Samsung ko 2000 ra Apple ko IPhone ko chai 200000 ho\n","\n","### response:\n","\n","Samsung ko price 2000 ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"Puma shoe ko price kati ho\",\n","        context=\"Product: Puma Running Shoes, Price: Rs. 9,999, Features: Lightweight, Sizes: 6-12\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hHU_AV8P6YBo","executionInfo":{"status":"ok","timestamp":1736963758344,"user_tz":-345,"elapsed":4112,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"74c7f155-bf5c-411c-dbb2-a13b58957b7e"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","Puma shoe ko price kati ho\n","\n","### input:\n","Product: Puma Running Shoes, Price: Rs. 9,999, Features: Lightweight, Sizes: 6-12\n","\n","### response:\n","\n","Puma Running Shoes ko price Rs. 9,999 ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"Return kati din samma garna paincha\",\n","        context=\"Platform ko furniture section ma sofas, beds, ra tables jasari items available cha. Delivery timing 10-15 din samma lagcha, ra return policy sirf unused items ko lagi 7 din samma cha. EMI options available cha jaha users le monthly installments ko suwidha lin sakchha.\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eh0yg3Yc6uNl","executionInfo":{"status":"ok","timestamp":1736963777876,"user_tz":-345,"elapsed":8769,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"bc408bf8-e690-4f49-b9c4-338c041383dc"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","Return kati din samma garna paincha\n","\n","### input:\n","Platform ko furniture section ma sofas, beds, ra tables jasari items available cha. Delivery timing 10-15 din samma lagcha, ra return policy sirf unused items ko lagi 7 din samma cha. EMI options available cha jaha users le monthly installments ko suwidha lin sakchha.\n","\n","### response:\n","\n","Platform ko furniture section ma sofas, beds, ra tables jasari items available cha. Delivery timing 10-15 din samma lagcha, ra return policy sirf unused items ko lagi 7 din samma cha. EMI options available cha jaha users le monthly installments ko suwidha lin sakchha.\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"Where is the store located\",\n","        context=\"Our store is located in Dharan we sell all kinds of electronics and we accept payment method from esewa khalti wallet now no discounts are available and we are offering 20 percent discount on purchase above 2000\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FqztCMPu7XJw","executionInfo":{"status":"ok","timestamp":1736963791047,"user_tz":-345,"elapsed":832,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"58a6c955-87aa-4b18-f144-b808aaf05b65"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","Where is the store located\n","\n","### input:\n","Our store is located in Dharan we sell all kinds of electronics and we accept payment method from esewa khalti wallet now no discounts are available and we are offering 20 percent discount on purchase above 2000\n","\n","### response:\n","\n","Store Dharan\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"how can I pay\",\n","        context=\"Our store is located in Dharan we sell all kinds of electronics and we accept payment method from esewa khalti wallet now no discounts are available and we are offering 20 percent discount on purchase above 2000\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MYTmsn5I7qGu","executionInfo":{"status":"ok","timestamp":1736963801546,"user_tz":-345,"elapsed":2181,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"d96675fe-32ae-4db5-f03d-ab6d2e6055f3"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","how can I pay\n","\n","### input:\n","Our store is located in Dharan we sell all kinds of electronics and we accept payment method from esewa khalti wallet now no discounts are available and we are offering 20 percent discount on purchase above 2000\n","\n","### response:\n","\n","Esewa khalti wallet ma pay garna sakchha.\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        instruction=\"Tala ko context herera, answer vana\",\n","        question=\"k k baata pay garna milxa\",\n","        context=\"We accept payment from esewa, khalti and our store is in Dharan\", # input\n","        response=\"\", # response\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","response = tokenizer.batch_decode(outputs)\n","print(response[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjdiWYcrzHYK","executionInfo":{"status":"ok","timestamp":1736963814911,"user_tz":-345,"elapsed":2531,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"5040edf1-edf9-43e1-d667-03a2f45417cc"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","k k baata pay garna milxa\n","\n","### input:\n","We accept payment from esewa, khalti and our store is in Dharan\n","\n","### response:\n","\n","Esewa, khalti ma payment accept garna huncha.\n","<eos>\n"]}]},{"cell_type":"markdown","metadata":{"id":"CrSvZObor0lY"},"source":[" You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e2pEuRb1r2Vg","outputId":"1a368398-6e0e-40cd-a62f-2d48b9dccfeb","executionInfo":{"status":"ok","timestamp":1736963832316,"user_tz":-345,"elapsed":1752,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>talako instruction herera answer deu\n","\n","    ### question\n","    store ma k k available xa\n","\n","    ### context\n","    hamro store ko name All Electronics store ho ra yaha sabai prakar ko electronics saman paincha\n","\n","    ### response\n","    All Electronics store ma sabai prakar ko electronics saman available cha.\n","<eos>\n"]}],"source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    \"\"\"talako instruction herera answer deu\n","\n","    ### question\n","    store ma k k available xa\n","\n","    ### context\n","    hamro store ko name All Electronics store ho ra yaha sabai prakar ko electronics saman paincha\n","\n","    ### response\n","    \"\"\"\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    \"\"\"talako instruction herera answer deu\n","\n","    ### question\n","    kun kun payment method baata pay garna sakinxa\n","\n","    ### context\n","    Hamro store Dharan ma xa hamro store ma sabai prakar ko electronics saman paincha ra hami esewa, khalti, imepay baata payment accept garxau\n","\n","    ### response\n","    \"\"\"\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_BsywA0xDQv","executionInfo":{"status":"ok","timestamp":1736963863725,"user_tz":-345,"elapsed":1723,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"1182abac-ae27-43e3-9e66-c97bf27bb38c"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>talako instruction herera answer deu\n","\n","    ### question\n","    kun kun payment method baata pay garna sakinxa\n","\n","    ### context\n","    Hamro store Dharan ma xa hamro store ma sabai prakar ko electronics saman paincha ra hami esewa, khalti, imepay baata payment accept garxau\n","\n","    ### response\n","    Payment accept garna esewa, khalti, imepay ma use garna sakchha.\n","<eos>\n"]}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    \"\"\"talako instruction herera answer deu\n","\n","    ### question\n","    Iphone ko price kati ho?\n","\n","    ### context\n","    Hamro store ko name All Electronics Store ho ra hami sanga aile Iphone ko Rs. 2 lakh rupaiya parcha ra redmi 10000 parcha\n","\n","    ### response\n","    \"\"\"\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__4JxRB80V_f","executionInfo":{"status":"ok","timestamp":1736963887043,"user_tz":-345,"elapsed":2610,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"c1e867b7-c60b-47fa-e14f-e94578a97f1d"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>talako instruction herera answer deu\n","\n","    ### question\n","    Iphone ko price kati ho?\n","\n","    ### context\n","    Hamro store ko name All Electronics Store ho ra hami sanga aile Iphone ko Rs. 2 lakh rupaiya parcha ra redmi 10000 parcha\n","\n","    ### response\n","    Iphone ko price Rs. 2 lakh rupaiya ho.\n","<eos>\n"]}]},{"cell_type":"markdown","source":["## Test on other question"],"metadata":{"id":"Dyv5EmTHHcB8"}},{"cell_type":"code","source":["def translate(query):\n","    inputs = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            instruction=\"Translate the given text from Roman Nepali to English\",\n","            question=query,\n","            context=\"\",\n","            response=\"\", # output - leave this blank for generation!\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"bQhO8SlHIZIn","executionInfo":{"status":"ok","timestamp":1736964979345,"user_tz":-345,"elapsed":431,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["translate(\"ma aaja dherei khushi xu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vG1S3NFoLj5T","executionInfo":{"status":"ok","timestamp":1736964992433,"user_tz":-345,"elapsed":1877,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"3676058c-749b-4f74-8847-4857c8468b61"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from Roman Nepali to English\n","\n","### question:\n","ma aaja dherei khushi xu\n","\n","### input:\n","\n","\n","### response:\n","\n","I'm feeling happy right now.\n","<eos>\n"]}]},{"cell_type":"code","source":["translate(\"Hami sabai ek jut vayera kaam garnu parxa\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZA6fjgKALn83","executionInfo":{"status":"ok","timestamp":1736965014569,"user_tz":-345,"elapsed":2112,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"854847d9-4f48-4317-821d-956732774398"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from Roman Nepali to English\n","\n","### question:\n","Hami sabai ek jut vayera kaam garnu parxa\n","\n","### input:\n","\n","\n","### response:\n","\n","I'm working on a project that requires all of us to collaborate.\n","<eos>\n"]}]},{"cell_type":"code","source":["translate(\"nepal auta word ko sundar desh ho\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FzqLslc2Lurq","executionInfo":{"status":"ok","timestamp":1736965046978,"user_tz":-345,"elapsed":1214,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"2b150a5b-5a52-4b30-8c6d-df87b908f419"},"execution_count":100,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from Roman Nepali to English\n","\n","### question:\n","nepal auta word ko sundar desh ho\n","\n","### input:\n","\n","\n","### response:\n","\n","Nepal is a beautiful country.\n","<eos>\n"]}]},{"cell_type":"code","source":["translate(\"what is the price of Samsung\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDbYRht7Iir_","executionInfo":{"status":"ok","timestamp":1736964195769,"user_tz":-345,"elapsed":1201,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"a21d2d24-d4d2-422d-ccdf-90f5028377c3"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from English to Roman Nepali\n","\n","### question:\n","what is the price of Samsung\n","\n","### input:\n","\n","\n","### response:\n","\n","Samsung ko price kasto ho?\n","<eos>\n"]}]},{"cell_type":"code","source":["translate(\"AI is Artificial Intelligence\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFWZ_C-JIlGx","executionInfo":{"status":"ok","timestamp":1736964243647,"user_tz":-345,"elapsed":1081,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"00c8c74a-6e00-4f7b-cfa8-8f1d3e7cfe3d"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from English to Roman Nepali\n","\n","### question:\n","AI is Artificial Intelligence\n","\n","### input:\n","\n","\n","### response:\n","\n","AI ko Artificial Intelligence ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["translate(\"what is the price of Redmi\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pm76jCwRIxBa","executionInfo":{"status":"ok","timestamp":1736964260785,"user_tz":-345,"elapsed":1094,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"0631703c-b181-45ee-8300-303d4fc37468"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from English to Roman Nepali\n","\n","### question:\n","what is the price of Redmi\n","\n","### input:\n","\n","\n","### response:\n","\n","Redmi ko price kasto ho?\n","<eos>\n"]}]},{"cell_type":"code","source":["translate(\"I am really happy today\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IynPCFJUI17_","executionInfo":{"status":"ok","timestamp":1736964294542,"user_tz":-345,"elapsed":1415,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7247e71a-ec10-4a6c-daed-1e1c299cdafb"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from English to Roman Nepali\n","\n","### question:\n","I am really happy today\n","\n","### input:\n","\n","\n","### response:\n","\n","Aaj haru haru ma khushi cha.\n","<eos>\n"]}]},{"cell_type":"code","source":["translate(\"I love Shiksha Education Knowledge korai\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9qSpxTCfJBYu","executionInfo":{"status":"ok","timestamp":1736964355463,"user_tz":-345,"elapsed":1663,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"976d33f8-162f-4859-d18b-85ff067b949e"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Translate the given text from English to Roman Nepali\n","\n","### question:\n","I love Shiksha Education Knowledge korai\n","\n","### input:\n","\n","\n","### response:\n","\n","Shiksha Education Knowledge ko lagi huncha.\n","<eos>\n"]}]},{"cell_type":"code","source":["def qa(query):\n","    inputs = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            instruction=\"User le gareko question lai, answer deu\",\n","            question=query,\n","            context=\"\",\n","            response=\"\", # output - leave this blank for generation!\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"3Fz261lWJO1b","executionInfo":{"status":"ok","timestamp":1736964445929,"user_tz":-345,"elapsed":432,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["qa(\"Nepal ko capital city kaha ho\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BcDQRLVoJh5w","executionInfo":{"status":"ok","timestamp":1736964459053,"user_tz":-345,"elapsed":1688,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"42c855d8-67ee-4d05-ad6a-99a941970b45"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu\n","\n","### question:\n","Nepal ko capital city kaha ho\n","\n","### input:\n","\n","\n","### response:\n","\n","Nepal ko capital city Kathmandu ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["qa(\"AI ko full form ke ho\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9QqbgPMKJlWh","executionInfo":{"status":"ok","timestamp":1736964489027,"user_tz":-345,"elapsed":1305,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"be457911-6cfd-4eae-aa66-3c0838bbd9c1"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu\n","\n","### question:\n","AI ko full form ke ho\n","\n","### input:\n","\n","\n","### response:\n","\n","AI ko full form 'Artificial Intelligence' ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["qa(\"India ko capital ka ho?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dfnoN7EpJs6F","executionInfo":{"status":"ok","timestamp":1736964677591,"user_tz":-345,"elapsed":1163,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"27f73aab-21d4-4e0b-8b37-a596f08330d4"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu\n","\n","### question:\n","India ko capital ka ho?\n","\n","### input:\n","\n","\n","### response:\n","\n","India ko capital Delhi ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["qa(\"Nepal ko ximeki desh kun kun ho\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJstmGlHKay8","executionInfo":{"status":"ok","timestamp":1736964761366,"user_tz":-345,"elapsed":1316,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"0c2bb37b-2e5e-421f-fbb9-dc3bff7b5738"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu\n","\n","### question:\n","Nepal ko ximeki desh kun kun ho\n","\n","### input:\n","\n","\n","### response:\n","\n","Nepal ko ximeki desh India ho.\n","<eos>\n"]}]},{"cell_type":"code","source":["qa(\"Microsoft ko headquarter kaha xa\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VWbIGrK6Kvgl","executionInfo":{"status":"ok","timestamp":1736964819500,"user_tz":-345,"elapsed":1616,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7cb20d37-5cff-4379-d0af-8f2bad04f18a"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu\n","\n","### question:\n","Microsoft ko headquarter kaha xa\n","\n","### input:\n","\n","\n","### response:\n","\n","Microsoft ko headquarter Redmond, Washington, USA ma cha.\n","<eos>\n"]}]},{"cell_type":"code","source":["qa(\"K baata payment garna milxa\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJ2oNxSdLEO_","executionInfo":{"status":"ok","timestamp":1736964941700,"user_tz":-345,"elapsed":1641,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"9b0d48d2-e82d-4d10-ffe2-88d251ec875d"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu\n","\n","### question:\n","K baata payment garna milxa\n","\n","### input:\n","\n","\n","### response:\n","\n","Payment garna online payment ma, cash ma, ra card ma possible cha.\n","<eos>\n"]}]},{"cell_type":"code","source":["def generate_text(query):\n","    inputs = tokenizer(\n","    [\n","        alpaca_prompt.format(\n","            instruction=\"Tala ko context herera, answer vana\",\n","            question=query,\n","            context=\"Hamro store ko name All Electronics Store ho yo Dharan ma xa ra yaha mobile laptop tv calculator paincha. Hami nepali sabai location ma delivery garxau ra esewa khalti baata wa cash on delivery pani linxau\",\n","            response=\"\", # output - leave this blank for generation!\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"2lIhsH74lWir","executionInfo":{"status":"ok","timestamp":1736964447006,"user_tz":-345,"elapsed":2,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["generate_text(\"store ko name ke ho\")"],"metadata":{"id":"xCrY_xzHlgE0","executionInfo":{"status":"ok","timestamp":1736963949731,"user_tz":-345,"elapsed":878,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d35b65fb-6c3b-44cb-9362-6700761fe38e"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","store ko name ke ho\n","\n","### input:\n","Hamro store ko name All Electronics Store ho yo Dharan ma xa ra yaha mobile laptop tv calculator paincha. Hami nepali sabai location ma delivery garxau ra esewa khalti baata wa cash on delivery pani linxau\n","\n","### response:\n","\n","All Electronics Store\n","<eos>\n"]}]},{"cell_type":"code","source":["generate_text(\"k baata pay garna sakinxa\")"],"metadata":{"id":"dc0g55mLlsE1","executionInfo":{"status":"ok","timestamp":1736963956765,"user_tz":-345,"elapsed":2066,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"85d04977-86d9-447b-c685-1ea2015980f0"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","k baata pay garna sakinxa\n","\n","### input:\n","Hamro store ko name All Electronics Store ho yo Dharan ma xa ra yaha mobile laptop tv calculator paincha. Hami nepali sabai location ma delivery garxau ra esewa khalti baata wa cash on delivery pani linxau\n","\n","### response:\n","\n","All Electronics Store Dharan ma ra yaha mobile laptop tv calculator paincha.\n","<eos>\n"]}]},{"cell_type":"code","source":["generate_text(\"delivery option ke ke cha?\")"],"metadata":{"id":"--LPmBz-mL3j","executionInfo":{"status":"ok","timestamp":1736963965129,"user_tz":-345,"elapsed":2152,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b8f8212-5930-460d-d780-02eb60eb47fd"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","delivery option ke ke cha?\n","\n","### input:\n","Hamro store ko name All Electronics Store ho yo Dharan ma xa ra yaha mobile laptop tv calculator paincha. Hami nepali sabai location ma delivery garxau ra esewa khalti baata wa cash on delivery pani linxau\n","\n","### response:\n","\n","Delivery option ko ke cha cash on delivery ra yaha ko location ma delivery garxau.\n","<eos>\n"]}]},{"cell_type":"markdown","source":["## without the prompt that was used to train"],"metadata":{"id":"3X-OkA0YHuRV"}},{"cell_type":"code","source":["generate_text(\"what is AI?\")"],"metadata":{"id":"OoZSkSptm0Sr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736963993320,"user_tz":-345,"elapsed":3457,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"eb99e96f-4527-439b-99ea-da0b179cb45e"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","Tala ko context herera, answer vana\n","\n","### question:\n","what is AI?\n","\n","### input:\n","Hamro store ko name All Electronics Store ho yo Dharan ma xa ra yaha mobile laptop tv calculator paincha. Hami nepali sabai location ma delivery garxau ra esewa khalti baata wa cash on delivery pani linxau\n","\n","### response:\n","\n","AI ko meaning artificial intelligence ho, jasto machine learning ra deep learning ko use garcha.\n","<eos>\n"]}]},{"cell_type":"code","source":["def generate_text(query):\n","    prompt = \"Answer the user query about Ecommerce in Roman Nepali using context below and answer only what is needed ### Instruction {query} ### Context: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha. ### Response\"\n","    inputs = tokenizer(\n","    [\n","        prompt.format(\n","            query=query\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"HZFNhPHwm46k","executionInfo":{"status":"ok","timestamp":1736964056801,"user_tz":-345,"elapsed":1,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["generate_text(query=\"Store ko naam ke ho?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQMwL8_rnFKY","executionInfo":{"status":"ok","timestamp":1736964079471,"user_tz":-345,"elapsed":9229,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"f4338d8d-cc54-42c4-b7da-4ad463d45daa"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user query about Ecommerce in Roman Nepali using context below and answer only what is needed ### Instruction Store ko naam ke ho? ### Context: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha. ### Response: Happy Store ra 6 baje dekhi rati 5 baje samma khulcha.\n","User le question le answer deu.\n","\n","Answer:\n","User le question le answer deu.\n","\n","### Instruction: User le question le answer deu.\n","\n","### Question: Ecommerce ma product return policy k ho?\n","\n","### Context: Ecommerce ma product return policy ko barema batauna.\n","\n","### Response: Ecommerce ma product return policy ko barema product return policy ko barema batauna.\n","User le question answer deu.\n","\n","Answer:\n","User le question answer deu.\n","\n","### Instruction: User le question answer deu.\n","User le\n"]}]},{"cell_type":"code","source":["generate_text(query=\"Store ma k paucha?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVEDaeVuogd6","executionInfo":{"status":"ok","timestamp":1736964093848,"user_tz":-345,"elapsed":9416,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"529d433d-0c64-4177-8808-445bff30bb75"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>Answer the user query about Ecommerce in Roman Nepali using context below and answer only what is needed ### Instruction Store ma k paucha? ### Context: Hamro store ko naam happy store ho ra hami sabi prakar ko books haru bechchau Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha. ### Response: Happy Store ma sabai bhanda books haru bechcha.\n","User le product details ma question lai answer deu. ### Instruction: User le product details ma question lai answer deu. ### Question: Product ko size details k ho? ### Context: Product ko name 'Happy Socks' ho ra size 'S' ho.\n","User le product details ma question lai answer deu. ### Instruction: User le product details ma question lai answer deu. ### Question: Product ko color options k ho? ### Context: Product ko name 'Happy Socks' ho ra color options 'Blue', 'Green', ra 'Red' ho.\n","\n"]}]},{"cell_type":"code","source":["def generate_text(query):\n","    prompt = \"\"\"\n","    You are Ecommerce AI Assistant and will only answer about ecommerce queries in only Roman Nepali Language and will use the data below:\n","\n","    ### Context\n","    Hamro store ko naam happy store ho\n","    hami sabi prakar ko books haru bechchau\n","    Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha.\n","    Rato Tshirt ko price 1000 ho\n","    Nilo Tshirt ko price 2000 ho\n","    Nike jutta ko paisa 3000 ho\n","\n","    ### Question\n","    {query}\n","\n","    ### Response\n","    \"\"\"\n","    inputs = tokenizer(\n","    [\n","        prompt.format(\n","            query=query\n","        )\n","    ], return_tensors = \"pt\").to(\"cuda\")\n","\n","    from transformers import TextStreamer\n","    text_streamer = TextStreamer(tokenizer)\n","    _ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"RcQXyrLQqGwD","executionInfo":{"status":"ok","timestamp":1736964100174,"user_tz":-345,"elapsed":396,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["generate_text(\"store ko name ke ho?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tW7DHQ-SqzMH","executionInfo":{"status":"ok","timestamp":1736964103774,"user_tz":-345,"elapsed":984,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"338e5c4c-932e-4985-ec35-d3d8ff85529a"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","    You are Ecommerce AI Assistant and will only answer about ecommerce queries in only Roman Nepali Language and will use the data below:\n","\n","    ### Context\n","    Hamro store ko naam happy store ho\n","    hami sabi prakar ko books haru bechchau\n","    Hamro store bihan 6 baje dekhi rati 5 baje samma khulcha.\n","    Rato Tshirt ko price 1000 ho\n","    Nilo Tshirt ko price 2000 ho\n","    Nike jutta ko paisa 3000 ho\n","\n","    ### Question\n","    store ko name ke ho?\n","\n","    ### Response\n","    Happy Store ho.\n","<eos>\n"]}]},{"cell_type":"markdown","metadata":{"id":"uMuVrWbjAzhc"},"source":["<a name=\"Save\"></a>\n","### Saving, loading finetuned models\n","To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n","\n","**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"]},{"cell_type":"code","execution_count":107,"metadata":{"id":"upcOlWe7A1vc","colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["c8c6a061734a454bb051c0b41c55fd25","275e5d3023114e8caaddbc5c993e4554","ec387db891d245208e897a296395a982","f9dbeacd43284b2c915263a4d234136a","5674c20336984e9dad60983f30e985fc","615ee3205387427f8e2b5b654e5f6e5c","7adf41828372411c84611ff4c16a96e8","d1d738d0e802499ab5d2935edff2926e","71e59cc53be0474b8189b03af8648180","c28ce36a1726478eab08e9be200fe910","d1535d51cc31400798c0a404933f1832","0f09c12e99da4abe85da631683766854","61e9360a9fba4984ae74f41edc8c4bf5","d4e0ba2a660244c9bf4baf6bcd1f51b4","db9be5f2ecbc471f88cf876aa53b78c4","76de555bdbf842db89360ee2ae68cd63","09b08102189f43d5ab31bd2efadbfcda","36bfb3733ff446d58e29f37661db66e5","0d7268112fb543e38df258d5062fdcd0","9454d0e89e3c4b6ba74f8f59fd8592bb","f57f1dcbdb3244848a07182406a0cd7b","fdabc215a75644539ae66de3e2d78ccb","aa5fc26d1a0240d5a84f09c4fca5d4f0","dec9500d3fb444fcb9ca869232e69597","29dd992230b54e07a0dee2ab7eec1b41","faddeb6f362c4a5dacce4def3a245931","9e3ec1f201ff497f8a1afe82e45e6cce","40d7e91b1923402482c4246c8ab4dc1a","11baaa5d47534e48b2671c15ccf98204","5a979d5b7f0a41c08fbf5cf020b0fd0e","1247a6039aa44b508de447534fd9ab40","5695d65a1b6b406da93f3c2ee11fde7c","f244e56d7b2a4614bfadc9e012db08aa"]},"executionInfo":{"status":"ok","timestamp":1736965359698,"user_tz":-345,"elapsed":6675,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"5c186eb7-5d8a-4b54-c48d-f83009ffcd4a"},"outputs":[{"output_type":"stream","name":"stderr","text":["No files have been modified since last commit. Skipping to prevent empty commit.\n","WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"]},{"output_type":"stream","name":"stdout","text":["Saved model to https://huggingface.co/manojbaniya/best_01\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c6a061734a454bb051c0b41c55fd25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f09c12e99da4abe85da631683766854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa5fc26d1a0240d5a84f09c4fca5d4f0"}},"metadata":{}}],"source":["# model.save_pretrained(\"lora_model\") # Local saving\n","# tokenizer.save_pretrained(\"lora_model\")\n","model.push_to_hub(\"manojbaniya/best_01\", token = \"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\") # Online saving\n","tokenizer.push_to_hub(\"manojbaniya/best_01\", token = \"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\") # Online saving"]},{"cell_type":"markdown","metadata":{"id":"AEEcJ4qfC7Lp"},"source":["Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"MKX_XKs_BNZR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736965392575,"user_tz":-345,"elapsed":15843,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"684aa0c6-3917-4fd3-e280-11fda6f7504a"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.1.5: Fast Gemma2 patching. Transformers: 4.47.1.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"source":["if True:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"manojbaniya/best_01\", # MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference"]},{"cell_type":"code","source":["inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","            instruction=\"User le gareko question lai, answer deu\",\n","            question=\"Nepal ma kati wata zone xan\",\n","            context=\"\",\n","            response=\"\", # output - leave this blank for generation!\n","        )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ketFZnh0Mmi8","executionInfo":{"status":"ok","timestamp":1736965397113,"user_tz":-345,"elapsed":4545,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"887cd548-da85-42f1-907f-8f7b9dbb2d08"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["<bos>\n","Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n","\n","### instruction:\n","User le gareko question lai, answer deu\n","\n","### question:\n","Nepal ma kati wata zone xan\n","\n","### input:\n","\n","\n","### response:\n","\n","Nepal ma Himalaya, Terai, and Annapurna zone xan.\n","<eos>\n"]}]},{"cell_type":"markdown","metadata":{"id":"QQMjaNrjsU5_"},"source":["You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."]},{"cell_type":"code","execution_count":122,"metadata":{"id":"yFfaXG0WsQuE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736965777735,"user_tz":-345,"elapsed":13807,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"a9594508-1278-4a24-d5f9-5a363d729f9b"},"outputs":[{"output_type":"stream","name":"stderr","text":["The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"]}],"source":["if True:\n","    # use Unsloth if possible\n","    from peft import AutoPeftModelForCausalLM\n","    from transformers import AutoTokenizer\n","    model_peft = AutoPeftModelForCausalLM.from_pretrained(\n","        \"manojbaniya/best_01\", #  MODEL YOU USED FOR TRAINING\n","        load_in_4bit = load_in_4bit,\n","    )\n","    model_peft.base_model.model.config.max_position_embeddings = 2048\n","    tokenizer = AutoTokenizer.from_pretrained(\"manojbaniya/best_01\")"]},{"cell_type":"code","source":["inputs = tokenizer(\"store ko name ke ho\")\n","inputs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKiVPX0fNhUI","executionInfo":{"status":"ok","timestamp":1736965777735,"user_tz":-345,"elapsed":6,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"6acb2e4e-e8f2-4076-abdc-b1501f2932b2"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [2, 6709, 5778, 1503, 1708, 1965], 'attention_mask': [1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["input_tensor = torch.tensor(inputs[\"input_ids\"]).unsqueeze(0)\n","input_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhFufpuvNxnI","executionInfo":{"status":"ok","timestamp":1736965777736,"user_tz":-345,"elapsed":6,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"8d56dd79-1f2a-4c0a-cbb9-de1d8b3ae589"},"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   2, 6709, 5778, 1503, 1708, 1965]])"]},"metadata":{},"execution_count":124}]},{"cell_type":"code","source":["input_tensor = input_tensor.to(\"cuda\")\n","input_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRSIo12cOBBS","executionInfo":{"status":"ok","timestamp":1736965777736,"user_tz":-345,"elapsed":4,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"1451a376-21fb-4bf0-dc8d-cccb008d5ff3"},"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   2, 6709, 5778, 1503, 1708, 1965]], device='cuda:0')"]},"metadata":{},"execution_count":125}]},{"cell_type":"code","source":["# model_peft(input_tensor)"],"metadata":{"id":"FrxUzYKcOKjK","executionInfo":{"status":"ok","timestamp":1736965791026,"user_tz":-345,"elapsed":435,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}}},"execution_count":127,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f422JgM9sdVT"},"source":["### Saving to float16 for VLLM\n","\n","We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."]},{"cell_type":"code","execution_count":129,"metadata":{"id":"iHjt_SMYsd3P","colab":{"base_uri":"https://localhost:8080/","height":602,"referenced_widgets":["e15373592d6c45f784664158644bab9c","07a47b494d3747a786ea470a2085ab7a","ec8b3623300e499d95a71c8fb570fa77","5fddf02c69f9451abaaa2632ef6d1454","3da450ed417b44d69b43ca74cb067821","5a4dbff51ec84bbe85e6b107806397f0","127a94436d1f4f77996ad5a03e9749a0","8045dd23c5b64e0eaab042eacb6a2167","0fd661bc31504192b6160d54292d6136","c26acd2572ee450d9ef68be1a169e830","1e1a356d88344397b88cb91eedfbc43a","1e10edda436f4e27bb10fdfaff654d0f","13c6e034cf624e339ef80322ad9ea094","11063bb3ff2349a0a30670029a2f69d5","16acf90fe3ae4ff29d32394b3487e585","fd11b37aa94d439593d474bf3eb4feb6","a8fe9f4e16814fab8bb0f289be03549c","c6ff5498efa14d80ba5bc7fdcf5e8339","5bf9a991d3fc47469057712795e2bb40","f26756076454431599f2b8fc4297797f","486cfd970e3c49cd8dd0dc08c7e8b5cd","42c9903998bd40c6a597b6a0242ffb01","bb209bce6543472595b0c745b48bfdc5","bd5d06061cc54a63ba67b196ffabcf2d","b0d2f7b338a94acda399b28e8276d6b8","a650796ff1f44954b6ca540c7714c5dd","c34d8ed7b1e1462b91400c506795a384","83368dd448604131a28054819a6cbff4","5e1bb6173bf84ddc854a406fa27cf66a","a777407e0c2f4219ba84b4b2e4141a48","27f64124ddff48c7b04b68f18866ddf9","d6e1f7f20bb24277b1ba198fb39d5727","17d6e03d296e4361be095d50bd168333","81041d7298be462784380e237ad96972","2133a9bc9f3e4bd0850785e451a51409","740bc4e91fed45bfaaf03d2f6c69d60d","b9ffe7599d9a483c84df6cb9f7198bd2","253a46270e344977bfb6831233b77bf6","c3957321977b438abb0c6fbffde659a3","5e336914d80c42d2aa29434a7b12addc","13136f889a4a42a3be787d010416ee63","22bdac2952fc433b90568c8a800eb1ad","0ff2996146f74893b383f91a2e4b1c3d","390f19db9e2b497fad609e9141182140","53c95dd685ed441f8c82f4e3d7f7490d","573fa0f45d364e89a9c6db4d70378042","670e678c76cb45bea532a32df2462599","ee4a3e410db943b5b91de8999b35faf8","981b833213d247cd8bbd3c9c869369ec","28f3531ec5c847cf875093288afb66e4","fba2d1c0ee8d4397993787ce116f5ab9","43465e82cb984103b4a350edba41d1ee","b93b6a52190340969131123c1d30934f","23a77d3ea7cc4fa48df720608b44f53e","72946e764c204af99177d76732a8e0f2","8dd8a3135899489a85679b08889cc7fc","034ab4e7d4a84c1580b26782e10e00c5","0bba5740a4854092a01a9a7310081e0b","35e6b40bfce74ef6bd20b35bd4f5bc03","28161ee49c8a4201aaf9c1ccdcb193f6","afd060e1db3f4054aecafc3f234634bf","7bf0e1982717406ba34925ab56dbccad","4f7dd665cbb0469eb04590a44f45d2e4","63dee2bd30464ff89426b39a1be0daf8","447eaac2a69c467dad839d08e00b86f5","223f64da375b4744b10202fb5f125265","89b547e19cfa4d95aa8ddb7deb3a3866","cf98916b38ae4dafb98dc68700a4a235","bcdfddcd5b1948879b1f55e81bbeb6b1","3596a7674ada4040969f8d3c7db7ec23","23a2271dbc574992bfc5973b7f8b51b0","c8d3d840395646c48071e8c74da2ad43","1d8896fe2e4e4113be2e54a8f39e32c6","072b95fe3dfc46d39fcb258460a70dc7","4c1e8aebd61841b0a04e4d632ab7d348","25be4d32728a476d92f0e1c3f90a0f68","c7d201cd8f2c4442ae776390d139d314"]},"executionInfo":{"status":"ok","timestamp":1736966120048,"user_tz":-345,"elapsed":197836,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"9c26fef5-6b2d-4471-dc7a-b2f1249d0b03"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: You are pushing to hub, but you passed your HF username = manojbaniya.\n","We shall truncate manojbaniya/merged16bit to merged16bit\n","Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n","We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n","To force `safe_serialization`, set it to `None` instead.\n","Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 2.2G\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 4.18 out of 12.67 RAM for saving.\n","Unsloth: Saving model... This might take 5 minutes ...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/26 [00:00<?, ?it/s]\n","We will save to Disk and not RAM now.\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:20<00:00,  1.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Saving tokenizer..."]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e15373592d6c45f784664158644bab9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e10edda436f4e27bb10fdfaff654d0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/34.4M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb209bce6543472595b0c745b48bfdc5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Done.\n","Unsloth: Saving merged16bit/pytorch_model-00001-of-00002.bin...\n","Unsloth: Saving merged16bit/pytorch_model-00002-of-00002.bin...\n"]},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/580 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81041d7298be462784380e237ad96972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53c95dd685ed441f8c82f4e3d7f7490d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model-00001-of-00002.bin:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dd8a3135899489a85679b08889cc7fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model-00002-of-00002.bin:   0%|          | 0.00/241M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b547e19cfa4d95aa8ddb7deb3a3866"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Done.\n","Saved merged model to https://huggingface.co/manojbaniya/merged16bit\n"]}],"source":["# Merge to 16bit\n","if True: model.push_to_hub_merged(\"manojbaniya/merged16bit\", tokenizer, save_method = \"merged_16bit\", token = \"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\")"]},{"cell_type":"markdown","metadata":{"id":"TCv4vXHd61i7"},"source":["### GGUF / llama.cpp Conversion\n","To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n","\n","Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n","* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n","* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n","* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n","\n","[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"]},{"cell_type":"code","execution_count":130,"metadata":{"id":"FqfebeAdT073","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["680eb6a78cef4288abe0b86a12b0a885","5c648da225594587ae0aaf6c2f7c1265","c36f4263258c410d8fe7dd99b9ac0a66","6f1b38fe10264b8dbe0815ad1288f1cf","5fc4404902614332a5e83e9c65803e6e","b113ec83224a42a4883239bbabf5ea58","8c58d64cf80144d88e73c881144a3a89","f05f4e59f7e7476ab4631a8eaec8641e","62cd1beed89545bda773d00d2109e191","053dfae1897942ccbfd7b90b76022c1c","6852f5ef626f4f13b6505f7562b5e02d","fe388107d5bd4eb9be559a44f0e9cd56","84072963f71a4801b6998ad831e08f23","822a908d969547a1b0c7b5192243e55f","027c7ed6205b4c80ba51df950961bda1","001d8c5cc85e4708944ad3fdad35d45e","ae8cb3f3c37f4a87bf2b4455f78d0404","6984c09897b8456791671c333fc9fd60","66c89b915fae4a2484c4c234b51775a4","79c4dbf23f9a49ca8f8ee89eaadc0981","511f550e878a4002ab927a47ade436aa","424d269f47ed4a4f9410e51253d4d5ac"]},"executionInfo":{"status":"ok","timestamp":1736966705793,"user_tz":-345,"elapsed":584635,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"5c4df429-f2ff-457f-fd45-c0b32f5d3433"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 4.63 out of 12.67 RAM for saving.\n","Unsloth: Saving model... This might take 5 minutes ...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:34<00:00,  1.33s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Saving tokenizer... Done.\n","Unsloth: Saving manojbaniya/q4_GGUF/pytorch_model-00001-of-00002.bin...\n","Unsloth: Saving manojbaniya/q4_GGUF/pytorch_model-00002-of-00002.bin...\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Converting gemma2 model. Can use fast conversion = False.\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n","   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n","O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n","\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n"," \"-____-\"     In total, you will have to wait at least 16 minutes.\n","\n","Unsloth: Installing llama.cpp. This might take 3 minutes...\n","Unsloth: CMAKE detected. Finalizing some steps for installation.\n","Unsloth: [1] Converting model at manojbaniya/q4_GGUF into f16 GGUF format.\n","The output location will be /content/manojbaniya/q4_GGUF/unsloth.F16.gguf\n","This might take 3 minutes...\n","INFO:hf-to-gguf:Loading model: q4_GGUF\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00002.bin'\n","INFO:hf-to-gguf:token_embd.weight,                 torch.float16 --> F16, shape = {2304, 256000}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00002.bin'\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.float16 --> F16, shape = {2304, 2048}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.float16 --> F16, shape = {2304, 1024}\n","INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2304}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.float16 --> F16, shape = {2304, 9216}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.float16 --> F16, shape = {9216, 2304}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:output_norm.weight,                torch.float16 --> F32, shape = {2304}\n","INFO:hf-to-gguf:Set meta model\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:Set model tokenizer\n","INFO:gguf.vocab:Setting special token type bos to 2\n","INFO:gguf.vocab:Setting special token type eos to 1\n","INFO:gguf.vocab:Setting special token type unk to 3\n","INFO:gguf.vocab:Setting special token type pad to 0\n","INFO:gguf.vocab:Setting add_bos_token to True\n","INFO:gguf.vocab:Setting add_eos_token to False\n","INFO:hf-to-gguf:Set model quantization version\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:/content/manojbaniya/q4_GGUF/unsloth.F16.gguf: n_tensors = 288, total_size = 5.2G\n","Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.23G/5.23G [01:22<00:00, 63.8Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to /content/manojbaniya/q4_GGUF/unsloth.F16.gguf\n","Unsloth: Conversion completed! Output location: /content/manojbaniya/q4_GGUF/unsloth.F16.gguf\n","Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n","main: build = 4489 (f11cfdfd)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n","main: quantizing '/content/manojbaniya/q4_GGUF/unsloth.F16.gguf' to '/content/manojbaniya/q4_GGUF/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n","llama_model_loader: loaded meta data with 33 key-value pairs and 288 tensors from /content/manojbaniya/q4_GGUF/unsloth.F16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = Gemma 2 2b Bnb 4bit\n","llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n","llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n","llama_model_loader: - kv   5:                           general.basename str              = gemma-2\n","llama_model_loader: - kv   6:                         general.size_label str              = 2B\n","llama_model_loader: - kv   7:                      gemma2.context_length u32              = 8192\n","llama_model_loader: - kv   8:                    gemma2.embedding_length u32              = 2304\n","llama_model_loader: - kv   9:                         gemma2.block_count u32              = 26\n","llama_model_loader: - kv  10:                 gemma2.feed_forward_length u32              = 9216\n","llama_model_loader: - kv  11:                gemma2.attention.head_count u32              = 8\n","llama_model_loader: - kv  12:             gemma2.attention.head_count_kv u32              = 4\n","llama_model_loader: - kv  13:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n","llama_model_loader: - kv  14:                gemma2.attention.key_length u32              = 256\n","llama_model_loader: - kv  15:              gemma2.attention.value_length u32              = 256\n","llama_model_loader: - kv  16:                          general.file_type u32              = 1\n","llama_model_loader: - kv  17:              gemma2.attn_logit_softcapping f32              = 50.000000\n","llama_model_loader: - kv  18:             gemma2.final_logit_softcapping f32              = 30.000000\n","llama_model_loader: - kv  19:            gemma2.attention.sliding_window u32              = 4096\n","llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n","llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n","llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n","llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n","llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 2\n","llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 1\n","llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 3\n","llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n","llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n","llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n","llama_model_loader: - kv  31:            tokenizer.ggml.add_space_prefix bool             = false\n","llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:  105 tensors\n","llama_model_loader: - type  f16:  183 tensors\n","[   1/ 288]                   output_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[   2/ 288]                    token_embd.weight - [ 2304, 256000,     1,     1], type =    f16, converting to q6_K .. size =  1125.00 MiB ->   461.43 MiB\n","[   3/ 288]                  blk.0.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[   4/ 288]               blk.0.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[   5/ 288]             blk.0.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[   6/ 288]                  blk.0.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[   7/ 288]                  blk.0.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[   8/ 288]                blk.0.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[   9/ 288]                blk.0.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  10/ 288]                blk.0.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  11/ 288]                  blk.0.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  12/ 288]     blk.0.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  13/ 288]           blk.0.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  14/ 288]                  blk.1.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  15/ 288]               blk.1.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  16/ 288]             blk.1.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  17/ 288]                  blk.1.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  18/ 288]                  blk.1.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[  19/ 288]                blk.1.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[  20/ 288]                blk.1.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  21/ 288]                blk.1.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  22/ 288]                  blk.1.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  23/ 288]     blk.1.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  24/ 288]           blk.1.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  25/ 288]                  blk.2.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  26/ 288]               blk.2.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  27/ 288]             blk.2.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  28/ 288]                  blk.2.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  29/ 288]                  blk.2.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[  30/ 288]                blk.2.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[  31/ 288]                blk.2.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  32/ 288]                blk.2.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  33/ 288]                  blk.2.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  34/ 288]     blk.2.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  35/ 288]           blk.2.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  36/ 288]                  blk.3.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  37/ 288]               blk.3.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  38/ 288]             blk.3.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  39/ 288]                  blk.3.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  40/ 288]                  blk.3.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  41/ 288]                blk.3.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  42/ 288]                blk.3.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  43/ 288]                blk.3.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  44/ 288]                  blk.3.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  45/ 288]     blk.3.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  46/ 288]           blk.3.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  47/ 288]                  blk.4.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  48/ 288]               blk.4.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  49/ 288]             blk.4.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  50/ 288]                  blk.4.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  51/ 288]                  blk.4.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  52/ 288]                blk.4.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  53/ 288]                blk.4.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  54/ 288]                blk.4.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  55/ 288]                  blk.4.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  56/ 288]     blk.4.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  57/ 288]           blk.4.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  58/ 288]                  blk.5.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  59/ 288]               blk.5.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  60/ 288]             blk.5.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  61/ 288]                  blk.5.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  62/ 288]                  blk.5.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[  63/ 288]                blk.5.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[  64/ 288]                blk.5.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  65/ 288]                blk.5.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  66/ 288]                  blk.5.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  67/ 288]     blk.5.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  68/ 288]           blk.5.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  69/ 288]                  blk.6.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  70/ 288]               blk.6.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  71/ 288]             blk.6.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  72/ 288]                  blk.6.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  73/ 288]                  blk.6.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  74/ 288]                blk.6.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  75/ 288]                blk.6.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  76/ 288]                blk.6.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  77/ 288]                  blk.6.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  78/ 288]     blk.6.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  79/ 288]           blk.6.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  80/ 288]                  blk.7.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  81/ 288]               blk.7.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  82/ 288]             blk.7.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  83/ 288]                  blk.7.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  84/ 288]                  blk.7.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  85/ 288]                blk.7.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  86/ 288]                blk.7.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  87/ 288]                blk.7.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  88/ 288]                  blk.7.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  89/ 288]     blk.7.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  90/ 288]           blk.7.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  91/ 288]                  blk.8.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[  92/ 288]               blk.8.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  93/ 288]             blk.8.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  94/ 288]                  blk.8.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[  95/ 288]                  blk.8.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[  96/ 288]                blk.8.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[  97/ 288]                blk.8.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[  98/ 288]                blk.8.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[  99/ 288]                  blk.8.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 100/ 288]     blk.8.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 101/ 288]           blk.8.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 102/ 288]                  blk.9.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 103/ 288]               blk.9.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 104/ 288]             blk.9.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 105/ 288]                  blk.9.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 106/ 288]                  blk.9.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 107/ 288]                blk.9.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 108/ 288]                blk.9.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 109/ 288]                blk.9.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 110/ 288]                  blk.9.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 111/ 288]     blk.9.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 112/ 288]           blk.9.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 113/ 288]                 blk.10.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 114/ 288]              blk.10.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 115/ 288]            blk.10.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 116/ 288]                 blk.10.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 117/ 288]                 blk.10.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 118/ 288]               blk.10.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 119/ 288]               blk.10.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 120/ 288]               blk.10.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 121/ 288]                 blk.10.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 122/ 288]    blk.10.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 123/ 288]          blk.10.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 124/ 288]                 blk.11.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 125/ 288]              blk.11.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 126/ 288]            blk.11.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 127/ 288]                 blk.11.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 128/ 288]                 blk.11.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 129/ 288]               blk.11.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 130/ 288]               blk.11.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 131/ 288]               blk.11.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 132/ 288]                 blk.11.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 133/ 288]    blk.11.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 134/ 288]          blk.11.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 135/ 288]                 blk.12.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 136/ 288]              blk.12.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 137/ 288]            blk.12.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 138/ 288]                 blk.12.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 139/ 288]                 blk.12.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 140/ 288]               blk.12.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 141/ 288]               blk.12.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 142/ 288]               blk.12.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 143/ 288]                 blk.12.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 144/ 288]    blk.12.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 145/ 288]          blk.12.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 146/ 288]                 blk.13.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 147/ 288]              blk.13.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 148/ 288]            blk.13.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 149/ 288]                 blk.13.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 150/ 288]                 blk.13.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 151/ 288]               blk.13.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 152/ 288]               blk.13.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 153/ 288]               blk.13.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 154/ 288]                 blk.13.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 155/ 288]    blk.13.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 156/ 288]          blk.13.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 157/ 288]                 blk.14.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 158/ 288]              blk.14.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 159/ 288]            blk.14.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 160/ 288]                 blk.14.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 161/ 288]                 blk.14.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 162/ 288]               blk.14.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 163/ 288]               blk.14.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 164/ 288]               blk.14.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 165/ 288]                 blk.14.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 166/ 288]    blk.14.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 167/ 288]          blk.14.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 168/ 288]                 blk.15.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 169/ 288]              blk.15.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 170/ 288]            blk.15.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 171/ 288]                 blk.15.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 172/ 288]                 blk.15.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 173/ 288]               blk.15.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 174/ 288]               blk.15.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 175/ 288]               blk.15.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 176/ 288]                 blk.15.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 177/ 288]    blk.15.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 178/ 288]          blk.15.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 179/ 288]                 blk.16.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 180/ 288]              blk.16.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 181/ 288]            blk.16.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 182/ 288]                 blk.16.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 183/ 288]                 blk.16.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 184/ 288]               blk.16.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 185/ 288]               blk.16.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 186/ 288]               blk.16.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 187/ 288]                 blk.16.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 188/ 288]    blk.16.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 189/ 288]          blk.16.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 190/ 288]                 blk.17.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 191/ 288]              blk.17.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 192/ 288]            blk.17.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 193/ 288]                 blk.17.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 194/ 288]                 blk.17.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 195/ 288]               blk.17.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 196/ 288]               blk.17.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 197/ 288]               blk.17.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 198/ 288]                 blk.17.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 199/ 288]    blk.17.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 200/ 288]          blk.17.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 201/ 288]                 blk.18.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 202/ 288]              blk.18.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 203/ 288]            blk.18.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 204/ 288]                 blk.18.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 205/ 288]                 blk.18.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 206/ 288]               blk.18.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 207/ 288]               blk.18.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 208/ 288]               blk.18.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 209/ 288]                 blk.18.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 210/ 288]    blk.18.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 211/ 288]          blk.18.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 212/ 288]                 blk.19.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 213/ 288]              blk.19.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 214/ 288]            blk.19.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 215/ 288]                 blk.19.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 216/ 288]                 blk.19.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 217/ 288]               blk.19.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 218/ 288]               blk.19.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 219/ 288]               blk.19.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 220/ 288]                 blk.19.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 221/ 288]    blk.19.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 222/ 288]          blk.19.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 223/ 288]                 blk.20.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 224/ 288]              blk.20.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 225/ 288]            blk.20.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 226/ 288]                 blk.20.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 227/ 288]                 blk.20.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 228/ 288]               blk.20.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 229/ 288]               blk.20.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 230/ 288]               blk.20.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 231/ 288]                 blk.20.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 232/ 288]    blk.20.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 233/ 288]          blk.20.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 234/ 288]                 blk.21.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 235/ 288]              blk.21.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 236/ 288]            blk.21.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 237/ 288]                 blk.21.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 238/ 288]                 blk.21.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 239/ 288]               blk.21.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 240/ 288]               blk.21.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 241/ 288]               blk.21.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 242/ 288]                 blk.21.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 243/ 288]    blk.21.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 244/ 288]          blk.21.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 245/ 288]                 blk.22.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 246/ 288]              blk.22.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 247/ 288]            blk.22.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 248/ 288]                 blk.22.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 249/ 288]                 blk.22.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 250/ 288]               blk.22.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 251/ 288]               blk.22.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 252/ 288]               blk.22.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 253/ 288]                 blk.22.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 254/ 288]    blk.22.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 255/ 288]          blk.22.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 256/ 288]                 blk.23.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 257/ 288]              blk.23.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 258/ 288]            blk.23.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 259/ 288]                 blk.23.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 260/ 288]                 blk.23.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 261/ 288]               blk.23.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 262/ 288]               blk.23.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 263/ 288]               blk.23.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 264/ 288]                 blk.23.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 265/ 288]    blk.23.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 266/ 288]          blk.23.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 267/ 288]                 blk.24.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 268/ 288]              blk.24.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 269/ 288]            blk.24.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 270/ 288]                 blk.24.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 271/ 288]                 blk.24.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 272/ 288]               blk.24.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 273/ 288]               blk.24.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 274/ 288]               blk.24.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 275/ 288]                 blk.24.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 276/ 288]    blk.24.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 277/ 288]          blk.24.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 278/ 288]                 blk.25.attn_k.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n","[ 279/ 288]              blk.25.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 280/ 288]            blk.25.attn_output.weight - [ 2048,  2304,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 281/ 288]                 blk.25.attn_q.weight - [ 2304,  2048,     1,     1], type =    f16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n","[ 282/ 288]                 blk.25.attn_v.weight - [ 2304,  1024,     1,     1], type =    f16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n","[ 283/ 288]               blk.25.ffn_down.weight - [ 9216,  2304,     1,     1], type =    f16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n","[ 284/ 288]               blk.25.ffn_gate.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 285/ 288]               blk.25.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 286/ 288]                 blk.25.ffn_up.weight - [ 2304,  9216,     1,     1], type =    f16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n","[ 287/ 288]    blk.25.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","[ 288/ 288]          blk.25.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n","llama_model_quantize_impl: model size  =  4986.92 MB\n","llama_model_quantize_impl: quant size  =  1623.67 MB\n","\n","main: quantize time = 268288.35 ms\n","main:    total time = 268288.35 ms\n","Unsloth: Conversion completed! Output location: /content/manojbaniya/q4_GGUF/unsloth.Q4_K_M.gguf\n","Unsloth: Uploading GGUF to Huggingface Hub...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"680eb6a78cef4288abe0b86a12b0a885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["unsloth.Q4_K_M.gguf:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe388107d5bd4eb9be559a44f0e9cd56"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saved GGUF to https://huggingface.co/manojbaniya/q4_GGUF\n"]}],"source":["# Save to 8bit Q8_0\n","if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n","# Remember to go to https://huggingface.co/settings/tokens for a token!\n","# And change hf to your username!\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n","\n","# Save to 16bit GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n","if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n","\n","# Save to q4_k_m GGUF\n","if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n","if True: model.push_to_hub_gguf(\"manojbaniya/q4_GGUF\", tokenizer, quantization_method = \"q4_k_m\", token = \"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\")\n","\n","# Save to multiple GGUF options - much faster if you want multiple!\n","if False:\n","    model.push_to_hub_gguf(\n","        \"hf/model\", # Change hf to your username!\n","        tokenizer,\n","        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n","        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n","    )"]},{"cell_type":"markdown","metadata":{"id":"bDp0zNpwe6U_"},"source":["Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html).\n","\n","**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**"]},{"cell_type":"markdown","metadata":{"id":"Zt9CHJqO6p30"},"source":["And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n","\n","Some other links:\n","1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n","2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n","3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n","4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n","5. Mistral 7b [free Kaggle version](https://www.kaggle.com/code/danielhanchen/kaggle-mistral-7b-unsloth-notebook)\n","6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with ðŸ¤— HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n","7. `ChatML` for ShareGPT datasets, [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing)\n","8. Text completions like novel writing [notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing)\n","9. [**NEW**] We make Phi-3 Medium / Mini **2x faster**! See our [Phi-3 Medium notebook](https://colab.research.google.com/drive/1hhdhBa1j_hsymiW9m-WzxQtgqTH_NHqi?usp=sharing)\n","10. [**NEW**] We make Gemma-2 9b / 27b **2x faster**! See our [Gemma-2 9b notebook](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)\n","11. [**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)\n","12. [**NEW**] We make Mistral NeMo 12B 2x faster and fit in under 12GB of VRAM! [Mistral NeMo notebook](https://colab.research.google.com/drive/17d3U-CAIwzmbDRqbZ9NnpHxCkmXB6LZ0?usp=sharing)\n","13. [**NEW**] Llama 3.1 8b, 70b and 405b is here! We make it 2x faster and use 60% less VRAM. [Llama 3.1 8b notebook](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing)\n","\n","<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n","</div>"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1weTpKOjBZxZJ5PQ-Ql8i6ptAY2x-FWVA","timestamp":1735142027225},{"file_id":"1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp","timestamp":1722408149017},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1721714808667},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bdca1aa73bc4400584d4e7168ca004db":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_814594086b7b4ad48745231c521c5e90","IPY_MODEL_ed0a2ff57a714ca49d1b1ec48d739a19","IPY_MODEL_ad3424ffa68947aa89f248d4d0f97411"],"layout":"IPY_MODEL_09b96432674d4f329c6c897920aeb16c"}},"814594086b7b4ad48745231c521c5e90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5222e518a3f4dc89e42b724b53ca88d","placeholder":"â€‹","style":"IPY_MODEL_0e936eb4eea64be592617c98f8e96851","value":"model.safetensors:â€‡100%"}},"ed0a2ff57a714ca49d1b1ec48d739a19":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_25875d2596f74e8893a43d0d11552410","max":2224765107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9da03c197bf84a23abeed3429bf04f89","value":2224764895}},"ad3424ffa68947aa89f248d4d0f97411":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a256b11a6e9411580bbb2882c58754e","placeholder":"â€‹","style":"IPY_MODEL_61b1ac7d56d54ab6a8ef0be22b29cb70","value":"â€‡2.22G/2.22Gâ€‡[00:22&lt;00:00,â€‡408MB/s]"}},"09b96432674d4f329c6c897920aeb16c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5222e518a3f4dc89e42b724b53ca88d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e936eb4eea64be592617c98f8e96851":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25875d2596f74e8893a43d0d11552410":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9da03c197bf84a23abeed3429bf04f89":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a256b11a6e9411580bbb2882c58754e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61b1ac7d56d54ab6a8ef0be22b29cb70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f8e5554aef54f6a90c3e39c3a1edc17":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d35b2c3c1e14b18b816b9db642f9869","IPY_MODEL_ef76eca2c8f3436fad8c10a886fca427","IPY_MODEL_a4dba1651bd74f0e8b2aaa1d75a4aec1"],"layout":"IPY_MODEL_039f71eb05d549e39e42be87e413a955"}},"2d35b2c3c1e14b18b816b9db642f9869":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b966e181a56d4da19acb8b3ac9368cb5","placeholder":"â€‹","style":"IPY_MODEL_d14ba115edf94a2a9353c9d42527e525","value":"generation_config.json:â€‡100%"}},"ef76eca2c8f3436fad8c10a886fca427":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5e00e7aa64546b1892da5cd88af354d","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02d21da0b2b14e77a61f176883679886","value":190}},"a4dba1651bd74f0e8b2aaa1d75a4aec1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b2a1ee94ce5429387b269b0271fa0dd","placeholder":"â€‹","style":"IPY_MODEL_5a4ac7a8d63b47ecb14fdc0301dcd33e","value":"â€‡190/190â€‡[00:00&lt;00:00,â€‡8.95kB/s]"}},"039f71eb05d549e39e42be87e413a955":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b966e181a56d4da19acb8b3ac9368cb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14ba115edf94a2a9353c9d42527e525":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5e00e7aa64546b1892da5cd88af354d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02d21da0b2b14e77a61f176883679886":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b2a1ee94ce5429387b269b0271fa0dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a4ac7a8d63b47ecb14fdc0301dcd33e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c590fe844a24df1a308cc1056c5ca55":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_deed436887344b309ba1629e433aa40d","IPY_MODEL_3892a56788f44a95bc681941e13ba646","IPY_MODEL_bcfd7215687d4642a0aba0e5879adb3b"],"layout":"IPY_MODEL_79f210cf976a42fba4c460d3e3d80e3e"}},"deed436887344b309ba1629e433aa40d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a7540a5b3424cff8e492b0cc7c38de6","placeholder":"â€‹","style":"IPY_MODEL_e152291fdb5d41e88b1d132e6aabc761","value":"tokenizer_config.json:â€‡100%"}},"3892a56788f44a95bc681941e13ba646":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_160ae4f1188c46e7a3ff3b773aaae0cb","max":46405,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74d236fe6479441798823f95ed1d15fd","value":46405}},"bcfd7215687d4642a0aba0e5879adb3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_171ae18d529444ce8dc050add2767d83","placeholder":"â€‹","style":"IPY_MODEL_a37e9f2e2ec745c985ab981bb08876bd","value":"â€‡46.4k/46.4kâ€‡[00:00&lt;00:00,â€‡2.88MB/s]"}},"79f210cf976a42fba4c460d3e3d80e3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a7540a5b3424cff8e492b0cc7c38de6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e152291fdb5d41e88b1d132e6aabc761":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"160ae4f1188c46e7a3ff3b773aaae0cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74d236fe6479441798823f95ed1d15fd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"171ae18d529444ce8dc050add2767d83":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a37e9f2e2ec745c985ab981bb08876bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f91b18b22924cc680f5a5cf45a9dd7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8bf36d8b984343f1929ed11eb78492ee","IPY_MODEL_d61154e2351f400eb7a395ec9c67fc46","IPY_MODEL_4279438872da4edfb5696ef29d7b872c"],"layout":"IPY_MODEL_65b406bf959d4f35848149491871582c"}},"8bf36d8b984343f1929ed11eb78492ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58be43afdfb54cfc8e6e5b0a141ccd76","placeholder":"â€‹","style":"IPY_MODEL_bf0672e39dd543b2847c425ed1b3b708","value":"tokenizer.model:â€‡100%"}},"d61154e2351f400eb7a395ec9c67fc46":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f7baf39a1af43eca6be4688784ae26f","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_966f0ab0ef634fe0b4daa3afcbcf4a52","value":4241003}},"4279438872da4edfb5696ef29d7b872c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc49e94519e3487a9f5a7f563892bde0","placeholder":"â€‹","style":"IPY_MODEL_90cdeacb2a764b938d10d3ca55041f06","value":"â€‡4.24M/4.24Mâ€‡[00:00&lt;00:00,â€‡19.8MB/s]"}},"65b406bf959d4f35848149491871582c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58be43afdfb54cfc8e6e5b0a141ccd76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0672e39dd543b2847c425ed1b3b708":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f7baf39a1af43eca6be4688784ae26f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"966f0ab0ef634fe0b4daa3afcbcf4a52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc49e94519e3487a9f5a7f563892bde0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90cdeacb2a764b938d10d3ca55041f06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee8e6469e4d2462a8d4f3b46f11bc540":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6019c070f6954d4cb3e4a4b546383d81","IPY_MODEL_aba9fffcb5ae4149b2ba66789a910fa0","IPY_MODEL_8144d03b54b34b7590f7004424e46a20"],"layout":"IPY_MODEL_1eee4d66be3a471292c26b75b2ba4a08"}},"6019c070f6954d4cb3e4a4b546383d81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b36574a521b441f6ba86e7e89d96db06","placeholder":"â€‹","style":"IPY_MODEL_7a55b3825c9c4966948ce56a2a33ea62","value":"special_tokens_map.json:â€‡100%"}},"aba9fffcb5ae4149b2ba66789a910fa0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b680479850394d0a880b3e3085cdb700","max":636,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eeee459d8a95404e8b5bcbb62bfbe72a","value":636}},"8144d03b54b34b7590f7004424e46a20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2c3fc8ddafe40eb85fea53c4f531ac2","placeholder":"â€‹","style":"IPY_MODEL_60dbe0b4dccf4bbc9b953111d05901ac","value":"â€‡636/636â€‡[00:00&lt;00:00,â€‡20.4kB/s]"}},"1eee4d66be3a471292c26b75b2ba4a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b36574a521b441f6ba86e7e89d96db06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a55b3825c9c4966948ce56a2a33ea62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b680479850394d0a880b3e3085cdb700":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eeee459d8a95404e8b5bcbb62bfbe72a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2c3fc8ddafe40eb85fea53c4f531ac2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60dbe0b4dccf4bbc9b953111d05901ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6d3de692ada4bdb9454d6e897f2594d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3c7f30612a9416f837ad44a88f50ffc","IPY_MODEL_70413fb43336433394e17763ba9d9b23","IPY_MODEL_fdae07c349ac49538794785e3d87ec74"],"layout":"IPY_MODEL_4e79626e1f0c4782a80d0182b046d35b"}},"c3c7f30612a9416f837ad44a88f50ffc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fdb674fe63d45b58a5957df3207a23d","placeholder":"â€‹","style":"IPY_MODEL_036cfd6a70164417b0fd1856208ffa25","value":"tokenizer.json:â€‡100%"}},"70413fb43336433394e17763ba9d9b23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14374b1e22d34b709d6092e63f031483","max":17525357,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fb464313a514350929ef2279731d36a","value":17525357}},"fdae07c349ac49538794785e3d87ec74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ab5a7f837dc4f35b13e646a7d0b1b9f","placeholder":"â€‹","style":"IPY_MODEL_28ba55ada38c453f86172847178ce36b","value":"â€‡17.5M/17.5Mâ€‡[00:00&lt;00:00,â€‡43.5MB/s]"}},"4e79626e1f0c4782a80d0182b046d35b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fdb674fe63d45b58a5957df3207a23d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"036cfd6a70164417b0fd1856208ffa25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14374b1e22d34b709d6092e63f031483":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fb464313a514350929ef2279731d36a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6ab5a7f837dc4f35b13e646a7d0b1b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28ba55ada38c453f86172847178ce36b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e3ccdd4074b40129f09d7d4eec7cc18":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb2f5d85f4d042999b5f46ddedc268dc","IPY_MODEL_eb2a06b94d0748baa98bc468d0306629","IPY_MODEL_d180a15e04544b8497001bf0dedc4d29"],"layout":"IPY_MODEL_6915cacc8ad54521a704beb3295d5638"}},"cb2f5d85f4d042999b5f46ddedc268dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fd6e005b47143b9b1b4db4d0d1b6c87","placeholder":"â€‹","style":"IPY_MODEL_7f8bf8b39b004f4d8ba8d16527d26a86","value":"README.md:â€‡100%"}},"eb2a06b94d0748baa98bc468d0306629":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f4d32c6a4f94c7e99c67fd62aac41ab","max":193,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d97d4f8dd804b21b3a3c3af7fc20ec2","value":193}},"d180a15e04544b8497001bf0dedc4d29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_02d32f7ec362404fb9c4ca00514a121a","placeholder":"â€‹","style":"IPY_MODEL_f57f45a0f48e41968e57fb4a979d6d00","value":"â€‡193/193â€‡[00:00&lt;00:00,â€‡5.20kB/s]"}},"6915cacc8ad54521a704beb3295d5638":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fd6e005b47143b9b1b4db4d0d1b6c87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f8bf8b39b004f4d8ba8d16527d26a86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f4d32c6a4f94c7e99c67fd62aac41ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d97d4f8dd804b21b3a3c3af7fc20ec2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02d32f7ec362404fb9c4ca00514a121a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f57f45a0f48e41968e57fb4a979d6d00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4228ed08916f44978c11cea1af67b776":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba228c5c260c499db041e8e6edd91786","IPY_MODEL_ba6bde9ba5ab4ec6aa9ae6c5d5af6d92","IPY_MODEL_41282503bf4c462ea2e83d955d6e64f0"],"layout":"IPY_MODEL_a3d7c0e904ea4897aef189ea4815e69d"}},"ba228c5c260c499db041e8e6edd91786":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ac900f513e449c296393c6015f64436","placeholder":"â€‹","style":"IPY_MODEL_427e9b62a3bd46f5b4404512a04817ed","value":"shuffled.csv:â€‡100%"}},"ba6bde9ba5ab4ec6aa9ae6c5d5af6d92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb18644670904129aa9e8a0124f39c9b","max":1831873,"min":0,"orientation":"horizontal","style":"IPY_MODEL_026d2927018c45b3bc4a4c7c943fd834","value":1831873}},"41282503bf4c462ea2e83d955d6e64f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a3da1730c1f47e28a854ba16f601e60","placeholder":"â€‹","style":"IPY_MODEL_8a84932ca13b434e9171abf124b8dcfb","value":"â€‡1.83M/1.83Mâ€‡[00:00&lt;00:00,â€‡19.2MB/s]"}},"a3d7c0e904ea4897aef189ea4815e69d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ac900f513e449c296393c6015f64436":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"427e9b62a3bd46f5b4404512a04817ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb18644670904129aa9e8a0124f39c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"026d2927018c45b3bc4a4c7c943fd834":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a3da1730c1f47e28a854ba16f601e60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a84932ca13b434e9171abf124b8dcfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c99655d41d14ac2a042c3c0deb08fea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acc24cbb8ca74021881c6de4e9a35c03","IPY_MODEL_3d4eb387cd374eb2bce2b67aca0b7018","IPY_MODEL_52076e0e1cef4e68b38348d77a4c91b2"],"layout":"IPY_MODEL_474e31a43dce4350adc07e638928fea1"}},"acc24cbb8ca74021881c6de4e9a35c03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cd042ebb472411a8b9d696339dee2ef","placeholder":"â€‹","style":"IPY_MODEL_1992ae052e3a4d11af194461cfa471e8","value":"Generatingâ€‡trainâ€‡split:â€‡"}},"3d4eb387cd374eb2bce2b67aca0b7018":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6942408aa89f4a35bfef40db33f1b2f3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3a6f870e19e4534a201ab2af415bcd6","value":1}},"52076e0e1cef4e68b38348d77a4c91b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a20b3727ee04f9680c7dc0c4554eff2","placeholder":"â€‹","style":"IPY_MODEL_e1e65d8bbe3543d5a5958db85a0716a9","value":"â€‡4768/0â€‡[00:00&lt;00:00,â€‡34155.83â€‡examples/s]"}},"474e31a43dce4350adc07e638928fea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cd042ebb472411a8b9d696339dee2ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1992ae052e3a4d11af194461cfa471e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6942408aa89f4a35bfef40db33f1b2f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d3a6f870e19e4534a201ab2af415bcd6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a20b3727ee04f9680c7dc0c4554eff2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1e65d8bbe3543d5a5958db85a0716a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58bfe71b94cc4c29b7b40f679973634a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7a7c7783ccd40419ebc6ce16b68f438","IPY_MODEL_da92b9aca9dd4a7b9dc219b57e3b03ab","IPY_MODEL_6ec33091dfd245f7b132161fff4dea7f"],"layout":"IPY_MODEL_b5bc3c3fab1e4de18fa6267aa6b4712c"}},"d7a7c7783ccd40419ebc6ce16b68f438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb88e667835c4216a2dd1786d3e3a26e","placeholder":"â€‹","style":"IPY_MODEL_3904d3ada66144cd9015e30467cbcb8b","value":"Map:â€‡100%"}},"da92b9aca9dd4a7b9dc219b57e3b03ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e9b4adb9148409e8e72ac1310eacb77","max":4768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_65bc4f5b982f4cf2966d9f0ba5daf038","value":4768}},"6ec33091dfd245f7b132161fff4dea7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89d6f4f5a133431abdcd7c8c8eb5112e","placeholder":"â€‹","style":"IPY_MODEL_2378d7be443a4a10803c2439235b02e6","value":"â€‡4768/4768â€‡[00:00&lt;00:00,â€‡25550.25â€‡examples/s]"}},"b5bc3c3fab1e4de18fa6267aa6b4712c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb88e667835c4216a2dd1786d3e3a26e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3904d3ada66144cd9015e30467cbcb8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e9b4adb9148409e8e72ac1310eacb77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65bc4f5b982f4cf2966d9f0ba5daf038":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89d6f4f5a133431abdcd7c8c8eb5112e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2378d7be443a4a10803c2439235b02e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"961e49cc0ee94712a1da4f4ce4fa8f67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46b8a9c11d1d4bc6ae605aa8e46eef5b","IPY_MODEL_2c08f581fd6741029df0ba83db042fdf","IPY_MODEL_56ed9b074f3f4a3182aa1e55cc1b6789"],"layout":"IPY_MODEL_4c53eb50f1104a09b6893b24a030997d"}},"46b8a9c11d1d4bc6ae605aa8e46eef5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69f7b062e10346bfbb17c29c122e242b","placeholder":"â€‹","style":"IPY_MODEL_c400ee86d06943c7884ee39b5ad879ea","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"2c08f581fd6741029df0ba83db042fdf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_444c1516d43e4101b52e9ca9f7533a4a","max":4768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b75b69007bf4f6eae903c1756dbddc7","value":4768}},"56ed9b074f3f4a3182aa1e55cc1b6789":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a737b6d75d0e4be6b22c5b39f7c67cdf","placeholder":"â€‹","style":"IPY_MODEL_a6f719f0b6a84842a98b9e35f678e0f8","value":"â€‡4768/4768â€‡[00:06&lt;00:00,â€‡1231.88â€‡examples/s]"}},"4c53eb50f1104a09b6893b24a030997d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69f7b062e10346bfbb17c29c122e242b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c400ee86d06943c7884ee39b5ad879ea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"444c1516d43e4101b52e9ca9f7533a4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b75b69007bf4f6eae903c1756dbddc7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a737b6d75d0e4be6b22c5b39f7c67cdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6f719f0b6a84842a98b9e35f678e0f8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8c6a061734a454bb051c0b41c55fd25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_275e5d3023114e8caaddbc5c993e4554","IPY_MODEL_ec387db891d245208e897a296395a982","IPY_MODEL_f9dbeacd43284b2c915263a4d234136a"],"layout":"IPY_MODEL_5674c20336984e9dad60983f30e985fc"}},"275e5d3023114e8caaddbc5c993e4554":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_615ee3205387427f8e2b5b654e5f6e5c","placeholder":"â€‹","style":"IPY_MODEL_7adf41828372411c84611ff4c16a96e8","value":"100%"}},"ec387db891d245208e897a296395a982":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1d738d0e802499ab5d2935edff2926e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71e59cc53be0474b8189b03af8648180","value":2}},"f9dbeacd43284b2c915263a4d234136a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c28ce36a1726478eab08e9be200fe910","placeholder":"â€‹","style":"IPY_MODEL_d1535d51cc31400798c0a404933f1832","value":"â€‡2/2â€‡[00:01&lt;00:00,â€‡â€‡1.02s/it]"}},"5674c20336984e9dad60983f30e985fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"615ee3205387427f8e2b5b654e5f6e5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7adf41828372411c84611ff4c16a96e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1d738d0e802499ab5d2935edff2926e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71e59cc53be0474b8189b03af8648180":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c28ce36a1726478eab08e9be200fe910":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1535d51cc31400798c0a404933f1832":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f09c12e99da4abe85da631683766854":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61e9360a9fba4984ae74f41edc8c4bf5","IPY_MODEL_d4e0ba2a660244c9bf4baf6bcd1f51b4","IPY_MODEL_db9be5f2ecbc471f88cf876aa53b78c4"],"layout":"IPY_MODEL_76de555bdbf842db89360ee2ae68cd63"}},"61e9360a9fba4984ae74f41edc8c4bf5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09b08102189f43d5ab31bd2efadbfcda","placeholder":"â€‹","style":"IPY_MODEL_36bfb3733ff446d58e29f37661db66e5","value":"tokenizer.model:â€‡"}},"d4e0ba2a660244c9bf4baf6bcd1f51b4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d7268112fb543e38df258d5062fdcd0","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9454d0e89e3c4b6ba74f8f59fd8592bb","value":4241003}},"db9be5f2ecbc471f88cf876aa53b78c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f57f1dcbdb3244848a07182406a0cd7b","placeholder":"â€‹","style":"IPY_MODEL_fdabc215a75644539ae66de3e2d78ccb","value":"â€‡16.0M/?â€‡[00:00&lt;00:00,â€‡28.8MB/s]"}},"76de555bdbf842db89360ee2ae68cd63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b08102189f43d5ab31bd2efadbfcda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36bfb3733ff446d58e29f37661db66e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d7268112fb543e38df258d5062fdcd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9454d0e89e3c4b6ba74f8f59fd8592bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f57f1dcbdb3244848a07182406a0cd7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdabc215a75644539ae66de3e2d78ccb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa5fc26d1a0240d5a84f09c4fca5d4f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dec9500d3fb444fcb9ca869232e69597","IPY_MODEL_29dd992230b54e07a0dee2ab7eec1b41","IPY_MODEL_faddeb6f362c4a5dacce4def3a245931"],"layout":"IPY_MODEL_9e3ec1f201ff497f8a1afe82e45e6cce"}},"dec9500d3fb444fcb9ca869232e69597":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40d7e91b1923402482c4246c8ab4dc1a","placeholder":"â€‹","style":"IPY_MODEL_11baaa5d47534e48b2671c15ccf98204","value":"tokenizer.json:â€‡"}},"29dd992230b54e07a0dee2ab7eec1b41":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a979d5b7f0a41c08fbf5cf020b0fd0e","max":34362873,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1247a6039aa44b508de447534fd9ab40","value":34362873}},"faddeb6f362c4a5dacce4def3a245931":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5695d65a1b6b406da93f3c2ee11fde7c","placeholder":"â€‹","style":"IPY_MODEL_f244e56d7b2a4614bfadc9e012db08aa","value":"â€‡48.0M/?â€‡[00:00&lt;00:00,â€‡58.4MB/s]"}},"9e3ec1f201ff497f8a1afe82e45e6cce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40d7e91b1923402482c4246c8ab4dc1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11baaa5d47534e48b2671c15ccf98204":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a979d5b7f0a41c08fbf5cf020b0fd0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1247a6039aa44b508de447534fd9ab40":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5695d65a1b6b406da93f3c2ee11fde7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f244e56d7b2a4614bfadc9e012db08aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e15373592d6c45f784664158644bab9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07a47b494d3747a786ea470a2085ab7a","IPY_MODEL_ec8b3623300e499d95a71c8fb570fa77","IPY_MODEL_5fddf02c69f9451abaaa2632ef6d1454"],"layout":"IPY_MODEL_3da450ed417b44d69b43ca74cb067821"}},"07a47b494d3747a786ea470a2085ab7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a4dbff51ec84bbe85e6b107806397f0","placeholder":"â€‹","style":"IPY_MODEL_127a94436d1f4f77996ad5a03e9749a0","value":"100%"}},"ec8b3623300e499d95a71c8fb570fa77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8045dd23c5b64e0eaab042eacb6a2167","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0fd661bc31504192b6160d54292d6136","value":2}},"5fddf02c69f9451abaaa2632ef6d1454":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c26acd2572ee450d9ef68be1a169e830","placeholder":"â€‹","style":"IPY_MODEL_1e1a356d88344397b88cb91eedfbc43a","value":"â€‡2/2â€‡[00:01&lt;00:00,â€‡â€‡1.01it/s]"}},"3da450ed417b44d69b43ca74cb067821":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a4dbff51ec84bbe85e6b107806397f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"127a94436d1f4f77996ad5a03e9749a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8045dd23c5b64e0eaab042eacb6a2167":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fd661bc31504192b6160d54292d6136":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c26acd2572ee450d9ef68be1a169e830":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e1a356d88344397b88cb91eedfbc43a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e10edda436f4e27bb10fdfaff654d0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13c6e034cf624e339ef80322ad9ea094","IPY_MODEL_11063bb3ff2349a0a30670029a2f69d5","IPY_MODEL_16acf90fe3ae4ff29d32394b3487e585"],"layout":"IPY_MODEL_fd11b37aa94d439593d474bf3eb4feb6"}},"13c6e034cf624e339ef80322ad9ea094":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8fe9f4e16814fab8bb0f289be03549c","placeholder":"â€‹","style":"IPY_MODEL_c6ff5498efa14d80ba5bc7fdcf5e8339","value":"tokenizer.model:â€‡"}},"11063bb3ff2349a0a30670029a2f69d5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bf9a991d3fc47469057712795e2bb40","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f26756076454431599f2b8fc4297797f","value":4241003}},"16acf90fe3ae4ff29d32394b3487e585":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_486cfd970e3c49cd8dd0dc08c7e8b5cd","placeholder":"â€‹","style":"IPY_MODEL_42c9903998bd40c6a597b6a0242ffb01","value":"â€‡16.0M/?â€‡[00:00&lt;00:00,â€‡21.7MB/s]"}},"fd11b37aa94d439593d474bf3eb4feb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8fe9f4e16814fab8bb0f289be03549c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ff5498efa14d80ba5bc7fdcf5e8339":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bf9a991d3fc47469057712795e2bb40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f26756076454431599f2b8fc4297797f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"486cfd970e3c49cd8dd0dc08c7e8b5cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42c9903998bd40c6a597b6a0242ffb01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb209bce6543472595b0c745b48bfdc5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd5d06061cc54a63ba67b196ffabcf2d","IPY_MODEL_b0d2f7b338a94acda399b28e8276d6b8","IPY_MODEL_a650796ff1f44954b6ca540c7714c5dd"],"layout":"IPY_MODEL_c34d8ed7b1e1462b91400c506795a384"}},"bd5d06061cc54a63ba67b196ffabcf2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83368dd448604131a28054819a6cbff4","placeholder":"â€‹","style":"IPY_MODEL_5e1bb6173bf84ddc854a406fa27cf66a","value":"tokenizer.json:â€‡"}},"b0d2f7b338a94acda399b28e8276d6b8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a777407e0c2f4219ba84b4b2e4141a48","max":34362873,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27f64124ddff48c7b04b68f18866ddf9","value":34362873}},"a650796ff1f44954b6ca540c7714c5dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6e1f7f20bb24277b1ba198fb39d5727","placeholder":"â€‹","style":"IPY_MODEL_17d6e03d296e4361be095d50bd168333","value":"â€‡48.0M/?â€‡[00:00&lt;00:00,â€‡41.7MB/s]"}},"c34d8ed7b1e1462b91400c506795a384":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83368dd448604131a28054819a6cbff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e1bb6173bf84ddc854a406fa27cf66a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a777407e0c2f4219ba84b4b2e4141a48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27f64124ddff48c7b04b68f18866ddf9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6e1f7f20bb24277b1ba198fb39d5727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17d6e03d296e4361be095d50bd168333":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81041d7298be462784380e237ad96972":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2133a9bc9f3e4bd0850785e451a51409","IPY_MODEL_740bc4e91fed45bfaaf03d2f6c69d60d","IPY_MODEL_b9ffe7599d9a483c84df6cb9f7198bd2"],"layout":"IPY_MODEL_253a46270e344977bfb6831233b77bf6"}},"2133a9bc9f3e4bd0850785e451a51409":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3957321977b438abb0c6fbffde659a3","placeholder":"â€‹","style":"IPY_MODEL_5e336914d80c42d2aa29434a7b12addc","value":"README.md:â€‡100%"}},"740bc4e91fed45bfaaf03d2f6c69d60d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_13136f889a4a42a3be787d010416ee63","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_22bdac2952fc433b90568c8a800eb1ad","value":580}},"b9ffe7599d9a483c84df6cb9f7198bd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ff2996146f74893b383f91a2e4b1c3d","placeholder":"â€‹","style":"IPY_MODEL_390f19db9e2b497fad609e9141182140","value":"â€‡580/580â€‡[00:00&lt;00:00,â€‡36.0kB/s]"}},"253a46270e344977bfb6831233b77bf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3957321977b438abb0c6fbffde659a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e336914d80c42d2aa29434a7b12addc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13136f889a4a42a3be787d010416ee63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22bdac2952fc433b90568c8a800eb1ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ff2996146f74893b383f91a2e4b1c3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"390f19db9e2b497fad609e9141182140":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53c95dd685ed441f8c82f4e3d7f7490d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_573fa0f45d364e89a9c6db4d70378042","IPY_MODEL_670e678c76cb45bea532a32df2462599","IPY_MODEL_ee4a3e410db943b5b91de8999b35faf8"],"layout":"IPY_MODEL_981b833213d247cd8bbd3c9c869369ec"}},"573fa0f45d364e89a9c6db4d70378042":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28f3531ec5c847cf875093288afb66e4","placeholder":"â€‹","style":"IPY_MODEL_fba2d1c0ee8d4397993787ce116f5ab9","value":"100%"}},"670e678c76cb45bea532a32df2462599":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43465e82cb984103b4a350edba41d1ee","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b93b6a52190340969131123c1d30934f","value":2}},"ee4a3e410db943b5b91de8999b35faf8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23a77d3ea7cc4fa48df720608b44f53e","placeholder":"â€‹","style":"IPY_MODEL_72946e764c204af99177d76732a8e0f2","value":"â€‡2/2â€‡[00:46&lt;00:00,â€‡19.62s/it]"}},"981b833213d247cd8bbd3c9c869369ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28f3531ec5c847cf875093288afb66e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fba2d1c0ee8d4397993787ce116f5ab9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43465e82cb984103b4a350edba41d1ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b93b6a52190340969131123c1d30934f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23a77d3ea7cc4fa48df720608b44f53e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72946e764c204af99177d76732a8e0f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8dd8a3135899489a85679b08889cc7fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_034ab4e7d4a84c1580b26782e10e00c5","IPY_MODEL_0bba5740a4854092a01a9a7310081e0b","IPY_MODEL_35e6b40bfce74ef6bd20b35bd4f5bc03"],"layout":"IPY_MODEL_28161ee49c8a4201aaf9c1ccdcb193f6"}},"034ab4e7d4a84c1580b26782e10e00c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afd060e1db3f4054aecafc3f234634bf","placeholder":"â€‹","style":"IPY_MODEL_7bf0e1982717406ba34925ab56dbccad","value":"pytorch_model-00001-of-00002.bin:â€‡"}},"0bba5740a4854092a01a9a7310081e0b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f7dd665cbb0469eb04590a44f45d2e4","max":4988088012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63dee2bd30464ff89426b39a1be0daf8","value":4988088012}},"35e6b40bfce74ef6bd20b35bd4f5bc03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_447eaac2a69c467dad839d08e00b86f5","placeholder":"â€‹","style":"IPY_MODEL_223f64da375b4744b10202fb5f125265","value":"â€‡4.99G/?â€‡[00:43&lt;00:00,â€‡604MB/s]"}},"28161ee49c8a4201aaf9c1ccdcb193f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afd060e1db3f4054aecafc3f234634bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bf0e1982717406ba34925ab56dbccad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f7dd665cbb0469eb04590a44f45d2e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63dee2bd30464ff89426b39a1be0daf8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"447eaac2a69c467dad839d08e00b86f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"223f64da375b4744b10202fb5f125265":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89b547e19cfa4d95aa8ddb7deb3a3866":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf98916b38ae4dafb98dc68700a4a235","IPY_MODEL_bcdfddcd5b1948879b1f55e81bbeb6b1","IPY_MODEL_3596a7674ada4040969f8d3c7db7ec23"],"layout":"IPY_MODEL_23a2271dbc574992bfc5973b7f8b51b0"}},"cf98916b38ae4dafb98dc68700a4a235":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8d3d840395646c48071e8c74da2ad43","placeholder":"â€‹","style":"IPY_MODEL_1d8896fe2e4e4113be2e54a8f39e32c6","value":"pytorch_model-00002-of-00002.bin:â€‡"}},"bcdfddcd5b1948879b1f55e81bbeb6b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_072b95fe3dfc46d39fcb258460a70dc7","max":240696494,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c1e8aebd61841b0a04e4d632ab7d348","value":240696494}},"3596a7674ada4040969f8d3c7db7ec23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25be4d32728a476d92f0e1c3f90a0f68","placeholder":"â€‹","style":"IPY_MODEL_c7d201cd8f2c4442ae776390d139d314","value":"â€‡256M/?â€‡[00:02&lt;00:00,â€‡178MB/s]"}},"23a2271dbc574992bfc5973b7f8b51b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8d3d840395646c48071e8c74da2ad43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d8896fe2e4e4113be2e54a8f39e32c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"072b95fe3dfc46d39fcb258460a70dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c1e8aebd61841b0a04e4d632ab7d348":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"25be4d32728a476d92f0e1c3f90a0f68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7d201cd8f2c4442ae776390d139d314":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"680eb6a78cef4288abe0b86a12b0a885":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c648da225594587ae0aaf6c2f7c1265","IPY_MODEL_c36f4263258c410d8fe7dd99b9ac0a66","IPY_MODEL_6f1b38fe10264b8dbe0815ad1288f1cf"],"layout":"IPY_MODEL_5fc4404902614332a5e83e9c65803e6e"}},"5c648da225594587ae0aaf6c2f7c1265":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b113ec83224a42a4883239bbabf5ea58","placeholder":"â€‹","style":"IPY_MODEL_8c58d64cf80144d88e73c881144a3a89","value":"100%"}},"c36f4263258c410d8fe7dd99b9ac0a66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f05f4e59f7e7476ab4631a8eaec8641e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62cd1beed89545bda773d00d2109e191","value":1}},"6f1b38fe10264b8dbe0815ad1288f1cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_053dfae1897942ccbfd7b90b76022c1c","placeholder":"â€‹","style":"IPY_MODEL_6852f5ef626f4f13b6505f7562b5e02d","value":"â€‡1/1â€‡[00:15&lt;00:00,â€‡15.44s/it]"}},"5fc4404902614332a5e83e9c65803e6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b113ec83224a42a4883239bbabf5ea58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c58d64cf80144d88e73c881144a3a89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f05f4e59f7e7476ab4631a8eaec8641e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62cd1beed89545bda773d00d2109e191":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"053dfae1897942ccbfd7b90b76022c1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6852f5ef626f4f13b6505f7562b5e02d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe388107d5bd4eb9be559a44f0e9cd56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_84072963f71a4801b6998ad831e08f23","IPY_MODEL_822a908d969547a1b0c7b5192243e55f","IPY_MODEL_027c7ed6205b4c80ba51df950961bda1"],"layout":"IPY_MODEL_001d8c5cc85e4708944ad3fdad35d45e"}},"84072963f71a4801b6998ad831e08f23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae8cb3f3c37f4a87bf2b4455f78d0404","placeholder":"â€‹","style":"IPY_MODEL_6984c09897b8456791671c333fc9fd60","value":"unsloth.Q4_K_M.gguf:â€‡"}},"822a908d969547a1b0c7b5192243e55f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66c89b915fae4a2484c4c234b51775a4","max":1708581792,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79c4dbf23f9a49ca8f8ee89eaadc0981","value":1708581792}},"027c7ed6205b4c80ba51df950961bda1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_511f550e878a4002ab927a47ade436aa","placeholder":"â€‹","style":"IPY_MODEL_424d269f47ed4a4f9410e51253d4d5ac","value":"â€‡1.71G/?â€‡[00:15&lt;00:00,â€‡1.29GB/s]"}},"001d8c5cc85e4708944ad3fdad35d45e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae8cb3f3c37f4a87bf2b4455f78d0404":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6984c09897b8456791671c333fc9fd60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66c89b915fae4a2484c4c234b51775a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79c4dbf23f9a49ca8f8ee89eaadc0981":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"511f550e878a4002ab927a47ade436aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"424d269f47ed4a4f9410e51253d4d5ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}