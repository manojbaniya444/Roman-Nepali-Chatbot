{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDip-f9Fa5Dq"
   },
   "source": [
    "## Fine Tune on V4 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 25332,
     "status": "ok",
     "timestamp": 1737998280177,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "ZJHzDzKiaz2r"
   },
   "outputs": [],
   "source": [
    "# installing unsloth\n",
    "\n",
    "%%capture\n",
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "\n",
    "# Install Flash Attention 2 for softcapping support\n",
    "import torch\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40700,
     "status": "ok",
     "timestamp": 1737998320872,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "syJTyqxka_Qw",
    "outputId": "7fa1acc1-c268-4d4f-baac-7d4f8deb5897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.1.7: Fast Gemma2 patching. Transformers: 4.47.1.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\",\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3-mini-4k-instruct\",\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-2b-bnb-4bit\",\n",
    "]\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-2-2b\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cMrWDiMbAdZ"
   },
   "source": [
    "## Adding LORA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9227,
     "status": "ok",
     "timestamp": 1737998330097,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "wjymS2uWbBzC",
    "outputId": "8f920b8c-bc5d-443f-aa4d-c2009e2de6d3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.1.7 patched 26 layers with 26 QKV layers, 26 O layers and 26 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvVbw2B_bajO"
   },
   "source": [
    "## Dataset for Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737998330098,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "2fA5ERDebc78"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1018,
     "status": "ok",
     "timestamp": 1737998331112,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "H3Gk2RiybgZg"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"manojbaniya/ift-nepali-v5\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1737998331112,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "vKYbBqYUboZo",
    "outputId": "892d6ff4-a42f-467f-a7fe-d5bb963144ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['category', 'context', 'question', 'response', 'instruction', 'prompt'],\n",
       "    num_rows: 17866\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUBlXgpibrcl"
   },
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1737998331112,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "kcQbcUEzbzJh"
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1737998331113,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "GaP-dHzPb4l-"
   },
   "outputs": [],
   "source": [
    "def formatting_prompt(examples):\n",
    "  \"\"\"Add EOS_TOKEN at the end of every data\"\"\"\n",
    "  prompts = []\n",
    "\n",
    "  for prompt in examples[\"prompt\"]:\n",
    "    new_prompt = prompt + EOS_TOKEN\n",
    "    prompts.append(new_prompt)\n",
    "\n",
    "  return {\"new_prompts\": prompts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1737998331113,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "jQztUtjZcMLD"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(formatting_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1737998331113,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "f0D5mtSphh3O",
    "outputId": "30388ae1-9a4f-42ca-e9ff-5ca47241e55e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "\n",
      "        ### Instruction\n",
      "        Translate the text below from English to Nepali:\n",
      "        \n",
      "        ### Input\n",
      "        The rise of remote learning has made education more flexible and accessible to students worldwide.\n",
      "        \n",
      "        ### Response\n",
      "        Remote shiksha ko uday le shiksha lai dherai lachila ra sansar bhari ko bidyarthiharuko lagi sajilo banaideko cha.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[999][\"new_prompts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737998331113,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "xqxQiU8BcNhJ",
    "outputId": "14cc8c82-171c-4040-c5cc-00d26fdcb746"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Store ko contact details k xa?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store ko name [RST Fashion] ho, hamro store Chitwan ma xa, Narayangarh ma. Hamro contact number 056-123456 ho.\n",
      "        \n",
      "        ### Response\n",
      "        Hamro contact number 056-123456 ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[100][\"new_prompts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnyt3wfCcfwV"
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737998331113,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "9-6pw41AchhP"
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1381,
     "status": "ok",
     "timestamp": 1737998332488,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "zusFxP5wcmF4"
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"new_prompts\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        # max_steps = 100,\n",
    "        learning_rate = 1e-5,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 100,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.02,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737998332488,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "DC2FBUr-cqB-",
    "outputId": "7dc8708a-5d98-493b-e5a9-ede0d99b38c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4. Max memory = 14.748 GB.\n",
      "2.697 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4231495,
     "status": "ok",
     "timestamp": 1738002563978,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "gVL1t29ActlC",
    "outputId": "99afd9c1-4974-4fe7-a588-60fa14adb97f"
   },
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1738002563978,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "tg2gKdjidYub",
    "outputId": "c38ba66f-cb36-4b3c-8a59-e9b906d8aa33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2233, training_loss=1.151259276026629, metrics={'train_runtime': 4225.2202, 'train_samples_per_second': 4.228, 'train_steps_per_second': 0.528, 'total_flos': 2.963342510740685e+16, 'train_loss': 1.151259276026629, 'epoch': 0.9998880555244599})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VNcY3_SczAg"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738002563978,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "lYj6s468c0YK",
    "outputId": "f788fb17-2aed-4318-afa8-a4911deadbf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Gemma2ForCausalLM(\n",
       "      (model): Gemma2Model(\n",
       "        (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-25): 26 x Gemma2DecoderLayer(\n",
       "            (self_attn): Gemma2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): GemmaFixedRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Gemma2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2304, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=9216, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=9216, out_features=2304, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=9216, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "            (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "            (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "            (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws2s81dFdnb-"
   },
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738002563978,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "sNC_YvCxdrs1"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
    "\n",
    "        ### Instruction\n",
    "        {question}\n",
    "\n",
    "        ### Input\n",
    "        {context}\n",
    "\n",
    "        ### Response\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 2621,
     "status": "ok",
     "timestamp": 1738002566596,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "2l5rFElBex4j"
   },
   "outputs": [],
   "source": [
    "inputs = prompt_template.format(\n",
    "    question=\"Nepal ko capital city kaha ho?\",\n",
    "    context=\"\"\n",
    ")\n",
    "inputs = tokenizer([inputs], return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738002566597,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "w8QsmIWkfQ6t",
    "outputId": "bc4ecc86-41ff-4815-e47b-e1145c808572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Nepal ko capital city kaha ho?\n",
      "        \n",
      "        ### Input\n",
      "        \n",
      "        \n",
      "        ### Response\n",
      "        Nepal ko capital city Kathmandu ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "print(response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJkiBIaLgAiR"
   },
   "source": [
    "## Generating Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738002566597,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "7-ZfGV-BfXE8"
   },
   "outputs": [],
   "source": [
    "def generate_response(question, type=\"RAG\", context=None):\n",
    "  inputs = prompt_template.format(question=question, context=context)\n",
    "\n",
    "  inputs = tokenizer([inputs], return_tensors=\"pt\").to(\"cuda\")\n",
    "  outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True)\n",
    "  response = tokenizer.batch_decode(outputs)\n",
    "  return response[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1738002567295,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "nbBY0qHMfz_R",
    "outputId": "4f7e354a-54f4-4ede-f6ed-d7edfaa30115"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Nepal ko president ko ho?\n",
      "        \n",
      "        ### Input\n",
      "        None\n",
      "        \n",
      "        ### Response\n",
      "        Nepal ko president ko ho?\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Nepal ko president ko ho?\",\n",
    "    type=\"qa\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1738002567713,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "n2h1B33ugKyU",
    "outputId": "e708cd38-90df-4450-87f3-41efca0d0c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        China ko capital kaha ho?\n",
      "        \n",
      "        ### Input\n",
      "        None\n",
      "        \n",
      "        ### Response\n",
      "        China ko capital Beijing ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"China ko capital kaha ho?\",\n",
    "    type=\"qa\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1738002568715,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "mYWRT7bXgPRV",
    "outputId": "8fd0616f-f546-4d3d-8b42-75fd2f4bba3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        China ko population kati xa?\n",
      "        \n",
      "        ### Input\n",
      "        None\n",
      "        \n",
      "        ### Response\n",
      "        China ko population 1.4 billion ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"China ko population kati xa?\",\n",
    "    type=\"qa\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2056,
     "status": "ok",
     "timestamp": 1738002570770,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "z0Y3rIl6giad",
    "outputId": "537a8e92-ee98-4619-f1cd-6f2a00f69a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        coding kasari sikne\n",
      "        \n",
      "        ### Input\n",
      "        None\n",
      "        \n",
      "        ### Response\n",
      "        Coding sikne le online courses, tutorials, ra coding communities ma participate garne, ya personal projects ko lagi time set garne.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"coding kasari sikne\",\n",
    "    type=\"qa\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcEEyi3_g8Mg"
   },
   "source": [
    "## RAG for Ecommerce Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 689,
     "status": "ok",
     "timestamp": 1738002571457,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "VqBo_GzTg-Np",
    "outputId": "eab64921-4c6f-489f-9e7b-c88700f2a497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Store ko location kaha xa\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store ko name All Electronics store ho, hamro store Dharan maa xa.\n",
      "        \n",
      "        ### Response\n",
      "        Hamro store Dharan maa xa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Store ko location kaha xa\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro store ko name All Electronics store ho, hamro store Dharan maa xa.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697,
     "status": "ok",
     "timestamp": 1738002572153,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "3xxxtHXEhX9_",
    "outputId": "cf5af2d9-a7f7-437a-ff25-25f3534ec2d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        store ko name ke ho?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store ko name All Electronics store ho ra hamro store Dharan maa xa. Hamro store ko contact number 9800000000 ho\n",
      "        \n",
      "        ### Response\n",
      "        All Electronics store\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"store ko name ke ho?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro store ko name All Electronics store ho ra hamro store Dharan maa xa. Hamro store ko contact number 9800000000 ho\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1787,
     "status": "ok",
     "timestamp": 1738002573938,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "Sw4e0JElh7yA",
    "outputId": "de64a17f-78b3-432f-bb64-c8a8869d8617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        store ko contact kati ho?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store ko name All Electronics store ho ra hamro store Dharan maa xa. Hamro store ko contact number 9800000000 ho\n",
      "        \n",
      "        ### Response\n",
      "        Hamro store ko contact number 9800000000 ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"store ko contact kati ho?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro store ko name All Electronics store ho ra hamro store Dharan maa xa. Hamro store ko contact number 9800000000 ho\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1361,
     "status": "ok",
     "timestamp": 1738002575296,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "yG2zcY25iJ_U",
    "outputId": "9414dae4-1e67-429d-8990-7b9e1fec6f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        store ma k k available xa?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store ma electronics ko sabai saman xa, mobile, laptop, calculator, watch, camera haru pani xa.\n",
      "        \n",
      "        ### Response\n",
      "        Hamro store ma mobile, laptop, calculator, watch, camera haru xa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"store ma k k available xa?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro store ma electronics ko sabai saman xa, mobile, laptop, calculator, watch, camera haru pani xa.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1300,
     "status": "ok",
     "timestamp": 1738002576594,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "kkgMFsaoit3R",
    "outputId": "d938d1a6-4714-459d-9b32-4f41eebd3483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        store ma k k electronics saman xa?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store ma electronics ko sabai saman xa, mobile, laptop, calculator, watch, camera haru pani xa.\n",
      "        \n",
      "        ### Response\n",
      "        Hamro store ma mobile, laptop, calculator, watch, camera haru xa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"store ma k k electronics saman xa?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro store ma electronics ko sabai saman xa, mobile, laptop, calculator, watch, camera haru pani xa.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1738002577773,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "a5JIJ4jWiydy",
    "outputId": "1e4536ea-3117-45b3-aa70-40d9d5be44d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        k baata pay garna milxa?\n",
      "        \n",
      "        ### Input\n",
      "        esewa, khalti ra mobile bank baata pay garna milxa\n",
      "        \n",
      "        ### Response\n",
      "        esewa, khalti ra mobile bank bata pay garna milxa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"k baata pay garna milxa?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"esewa, khalti ra mobile bank baata pay garna milxa\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1412,
     "status": "ok",
     "timestamp": 1738002579183,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "Z6CUUuXLjDph",
    "outputId": "8b00511e-2b52-4920-c11a-a564e08d5b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        store ma k k painxa?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store ma musical instruments painxa jastei keyboard, guitars, haru\n",
      "        \n",
      "        ### Response\n",
      "        Hamro store ma musical instruments painxa jastei keyboard, guitars, haru.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"store ma k k painxa?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro store ma musical instruments painxa jastei keyboard, guitars, haru\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1752,
     "status": "ok",
     "timestamp": 1738002580933,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "Dp5Ic3FwjpqM",
    "outputId": "46a88ada-4b80-48ce-c860-c9595280fc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        macbook ko barema vana\n",
      "        \n",
      "        ### Input\n",
      "        Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 8GB RAM, 256GB SSD.\n",
      "        \n",
      "        ### Response\n",
      "        Hajur, MacBook Air M1 ko stock available chaina.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"macbook ko barema vana\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 8GB RAM, 256GB SSD.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738002580933,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "u8_w4LU2j45H",
    "outputId": "59cb851e-bc81-4952-9a64-488b1a69a49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        macbook ko price kati ho\n",
      "        \n",
      "        ### Input\n",
      "        Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 8GB RAM, 256GB SSD.\n",
      "        \n",
      "        ### Response\n",
      "        MacBook ko price 150000 ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"macbook ko price kati ho\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 8GB RAM, 256GB SSD.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1735,
     "status": "ok",
     "timestamp": 1738002582666,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "ylZP-RwPj-8Z",
    "outputId": "cab10f7c-2b2a-4c7c-b794-c16e7c9c4d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Redmi ko price kati Rs.ho\n",
      "        \n",
      "        ### Input\n",
      "        Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 8GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and 90 GB RAM\n",
      "        \n",
      "        ### Response\n",
      "        Redmi Note 9 pro ko price Rs. 10000 ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Redmi ko price kati Rs.ho\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 8GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and 90 GB RAM\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1715,
     "status": "ok",
     "timestamp": 1738002584379,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "bZlYR255kSir",
    "outputId": "e829ed33-3f4f-4d53-e658-8e47b63b8eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Macbook Air ko RAM kati xa?\n",
      "        \n",
      "        ### Input\n",
      "        Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 16GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and 12 GB RAM\n",
      "        \n",
      "        ### Response\n",
      "        MacBook Air ko RAM 16 GB ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Macbook Air ko RAM kati xa?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 16GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and 12 GB RAM\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1738002584771,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "9y0dU4sdlPgC",
    "outputId": "74b74ea9-9a9b-433a-95f7-dcb41d3ee70b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Redmi Note 9 pro ko RAM kati xa?\n",
      "        \n",
      "        ### Input\n",
      "        Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 16GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and RAM: 12 GB\n",
      "        \n",
      "        ### Response\n",
      "        Redmi Note 9 pro ko RAM 12 GB xa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Redmi Note 9 pro ko RAM kati xa?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 16GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and RAM: 12 GB\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1741,
     "status": "ok",
     "timestamp": 1738002586510,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "eZKoDdCFlYyZ",
    "outputId": "57cc788c-f340-44ce-b23a-d98b0bd2225c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Redmi Note 9 pro ko storage kati xa?\n",
      "        \n",
      "        ### Input\n",
      "        Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 16GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and RAM: 12 GB\n",
      "        \n",
      "        ### Response\n",
      "        Redmi Note 9 pro ko storage 128 GB xa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Redmi Note 9 pro ko storage kati xa?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Product Details: name: MacBook Air M1, price: 150000, stock: False, description: 13.3-inch Retina display, Apple M1 chip, 16GB RAM, 256GB SSD. name: Redmi Note 9 pro, price: 10000, stock: True, description: Xiaomi mobile with 128 GB storage and RAM: 12 GB\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1355,
     "status": "ok",
     "timestamp": 1738002587862,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "B8wo3Ye1lf9t",
    "outputId": "6e5e792a-f77f-4b43-ad9c-fe4b3f46d07e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        delivery cost kati ho?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro ma delivery all over Nepal hunxa. Inside Kathmandu free delivery hunxa ra outside Kathmandu Rs. 130 delivery charge laagxa. Delivery 3 din vitra hunxa.\n",
      "        \n",
      "        ### Response\n",
      "        Inside Kathmandu free delivery hunxa ra outside Kathmandu Rs. 130 charge laagxa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"delivery cost kati ho?\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro ma delivery all over Nepal hunxa. Inside Kathmandu free delivery hunxa ra outside Kathmandu Rs. 130 delivery charge laagxa. Delivery 3 din vitra hunxa.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2125,
     "status": "ok",
     "timestamp": 1738002589986,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "BTIlnKNglp6u",
    "outputId": "9c672e6a-ae3f-42e9-c305-5f08efa131af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        kati din ma delivery hunxa\n",
      "        \n",
      "        ### Input\n",
      "        Hamro ma delivery all over Nepal hunxa. Inside Dharan free delivery hunxa ra outside Dharan Rs. 130 delivery charge laagxa. Delivery 3 din vitra hunxa.\n",
      "        \n",
      "        ### Response\n",
      "        Dharan ma free delivery hunxa ra outside Dharan ma Rs. 130 charge lagcha.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"kati din ma delivery hunxa\",\n",
    "    type=\"RAG\",\n",
    "    context=\"Hamro ma delivery all over Nepal hunxa. Inside Dharan free delivery hunxa ra outside Dharan Rs. 130 delivery charge laagxa. Delivery 3 din vitra hunxa.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1735,
     "status": "ok",
     "timestamp": 1738002591719,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "tyNqev1Bl5yU",
    "outputId": "6e6ba8e9-3f65-4aeb-c100-8b481b4135ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        timi ko hau\n",
      "        \n",
      "        ### Input\n",
      "        You are an AI assistant for an e-commerce store and will explain your purpose.\n",
      "        \n",
      "        ### Response\n",
      "        ma ek e-commerce assistant hu.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"timi ko hau\",\n",
    "    type=\"RAG\",\n",
    "    context=\"You are an AI assistant for an e-commerce store and will explain your purpose.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1857,
     "status": "ok",
     "timestamp": 1738002851262,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "Zvg8gXKmCZDJ",
    "outputId": "18c9a549-1265-42ec-b2f0-cd9a39b1cee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Translate the text from English to Roman Nepali\n",
      "        \n",
      "        ### Input\n",
      "        Nepali is a beautiful country\n",
      "        \n",
      "        ### Response\n",
      "        Nepali ma dherai ramro desh ho\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Translate the text from English to Roman Nepali\",\n",
    "    type=\"translate\",\n",
    "    context=\"Nepali is a beautiful country\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2699,
     "status": "ok",
     "timestamp": 1738002929051,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "sunV7z7ECwZa",
    "outputId": "2c10a1fb-fcbb-4e75-b350-1ed6ae8ab8fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        5 ota apple ma 2 ota khada kati baaki rahanxa\n",
      "        \n",
      "        ### Input\n",
      "        \n",
      "        \n",
      "        ### Response\n",
      "        5 ota apple ma 2 ota khada 3 ota baaki rahanxa.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"5 ota apple ma 2 ota khada kati baaki rahanxa\",\n",
    "    type=\"\",\n",
    "    context=\"\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2091,
     "status": "ok",
     "timestamp": 1738003100924,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "EX3Qa0Q1DGWx",
    "outputId": "cbf850c8-692e-43f0-945a-de1e72cf4d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        mt everest ko height kati ho\n",
      "        \n",
      "        ### Input\n",
      "        \n",
      "        \n",
      "        ### Response\n",
      "        Mt Everest ko height 8848.86 meters ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"mt everest ko height kati ho\",\n",
    "    type=\"\",\n",
    "    context=\"\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1738003470808,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "igYSQTgiELLC",
    "outputId": "75873e91-8bc6-47f9-aeb1-c0e7224404d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        store ko name ke ho?\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store Dharan ma xa, hamro store ko name Happy store ho contact no 9812324890 ho\n",
      "        \n",
      "        ### Response\n",
      "        Hamro store ko name Happy store ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"store ko name ke ho?\",\n",
    "    type=\"\",\n",
    "    context=\"Hamro store Dharan ma xa, hamro store ko name Happy store ho contact no 9812324890 ho\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4060,
     "status": "ok",
     "timestamp": 1738003495584,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "F8UWbj_gFHO_",
    "outputId": "3fcc1b0d-3101-40f6-875c-9201613bccb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        store ko location ke ho ra contact kati ho\n",
      "        \n",
      "        ### Input\n",
      "        Hamro store Dharan ma xa, hamro store ko name Happy store ho contact no 9812324890 ho\n",
      "        \n",
      "        ### Response\n",
      "        Hamro store Dharan ma xa, contact no 9812324890 ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"store ko location ke ho ra contact kati ho\",\n",
    "    type=\"\",\n",
    "    context=\"Hamro store Dharan ma xa, hamro store ko name Happy store ho contact no 9812324890 ho\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1738002751207,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "F5cMowwECSm4",
    "outputId": "0aa9b3d3-4a43-4b03-e108-04f0483ea05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        timi ko hau\n",
      "        \n",
      "        ### Input\n",
      "        You are an AI assistant for an Stock Customer support and will explain your purpose.\n",
      "        \n",
      "        ### Response\n",
      "        ma ek Stock Customer support assistant hu.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"timi ko hau\",\n",
    "    type=\"RAG\",\n",
    "    context=\"You are an AI assistant for an Stock Customer support and will explain your purpose.\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5493,
     "status": "ok",
     "timestamp": 1738003617244,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "G4_ou0iKFPlL",
    "outputId": "99ff822a-e922-480b-a77a-9d933f2dee09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Japan ko popular cities haru list gara\n",
      "        \n",
      "        ### Input\n",
      "        \n",
      "        \n",
      "        ### Response\n",
      "        Japan ko popular cities haru list garna: Tokyo, Osaka, Kyoto, Nagoya, Hiroshima, Sapporo, Fukuoka, Okinawa, Kobe, Yokohama.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Japan ko popular cities haru list gara\",\n",
    "    type=\"RAG\",\n",
    "    context=\"\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1738003660634,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "VXhNSa_YFtlp",
    "outputId": "3b8aa580-88ff-45c3-d7d3-6f44cf787cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        japan ko capital city tokyo ho vane India ko kaha ho\n",
      "        \n",
      "        ### Input\n",
      "        \n",
      "        \n",
      "        ### Response\n",
      "        India ko capital city Delhi ho.\n",
      "        <eos>\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"japan ko capital city tokyo ho vane India ko kaha ho\",\n",
    "    type=\"RAG\",\n",
    "    context=\"\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2767,
     "status": "ok",
     "timestamp": 1738002594484,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "28leyyzOmXGL",
    "outputId": "7f3622c6-bafe-422a-9e77-8a522cf7a0ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>\n",
      "        Below is an instruction that describes a task paired with an input that provides further context. Write a response that appriately complete the request.\n",
      "        \n",
      "        ### Instruction\n",
      "        Tell a short story in Nepali\n",
      "        \n",
      "        ### Input\n",
      "        None\n",
      "        \n",
      "        ### Response\n",
      "        Ek din ek ghar ma ek mandir ko jana aaye. Usle ghar ko sabai bhanda khusi rakhne ko lagi ek mandir ko jana le mandir ko jana le mandir ko jana le mandir ko jana le mandir ko jana le mandir\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(\n",
    "    question=\"Tell a short story in Nepali\",\n",
    "    type=\"instruction\",\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGhL_21DqBRl"
   },
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "04399ce45189481696bb8950f6d9f677",
      "8026ff65313f475494a9e832608b4506",
      "f39ce7858dcd4a2ebe9d028987ab7dc9",
      "2b10da20342c49aeb402add6ab68e4cc",
      "cba3099574974ee2a0efe97886ba379c",
      "6f2574a24cb34f86837a2f605fb4f240",
      "44d94ab5f3784298baa5aab63c71f9b9",
      "219f11c70431466da22aa8aae51c74c6",
      "da1ebe61cc1b46c598862e75dce760bc",
      "5febebe686924824b61c237555dfc8dc",
      "824f0b0594da456b8fb81b2ff57279ac",
      "60eb8e1cc0514abe888c6fe73dee4680",
      "963d23101b2244a7b5611a5f1d422ba8",
      "d3321d3a55754146a03d34fa8e87b27e",
      "dd65a939d7f14a7fa71e8c724e278e4e",
      "93f358f852dd4b9d8dfc4e14bc85da13",
      "b92799d96032440dabd4ba36f9e11235",
      "4df4b81e949c48c7bf6997702beab34f",
      "50edb18a04794cb19055313b828e8b26",
      "71edaf7b5deb414fab8085de14d3bba3",
      "f0bdd86e18ac41938830a19de864404a",
      "14cc5f8d7f794c31b289a148654beb74"
     ]
    },
    "executionInfo": {
     "elapsed": 7050,
     "status": "ok",
     "timestamp": 1738002601531,
     "user": {
      "displayName": "Manoj Kumar Baniya",
      "userId": "17588784896461812175"
     },
     "user_tz": -345
    },
    "id": "SGYb_WuKqDbL",
    "outputId": "868c9974-cb3a-49a9-fba6-c98ef3cddbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving LoRA adapters. Please wait...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04399ce45189481696bb8950f6d9f677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60eb8e1cc0514abe888c6fe73dee4680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/83.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lora model to https://huggingface.co/manojbaniya/best_v5_2\n"
     ]
    }
   ],
   "source": [
    "if True: model.push_to_hub_merged(\"manojbaniya/best_v5_2\", tokenizer, save_method = \"lora\", token = \"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\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04399ce45189481696bb8950f6d9f677": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8026ff65313f475494a9e832608b4506",
       "IPY_MODEL_f39ce7858dcd4a2ebe9d028987ab7dc9",
       "IPY_MODEL_2b10da20342c49aeb402add6ab68e4cc"
      ],
      "layout": "IPY_MODEL_cba3099574974ee2a0efe97886ba379c"
     }
    },
    "14cc5f8d7f794c31b289a148654beb74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "219f11c70431466da22aa8aae51c74c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b10da20342c49aeb402add6ab68e4cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5febebe686924824b61c237555dfc8dc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_824f0b0594da456b8fb81b2ff57279ac",
      "value": "â€‡1/1â€‡[00:01&lt;00:00,â€‡â€‡1.35s/it]"
     }
    },
    "44d94ab5f3784298baa5aab63c71f9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4df4b81e949c48c7bf6997702beab34f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50edb18a04794cb19055313b828e8b26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5febebe686924824b61c237555dfc8dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60eb8e1cc0514abe888c6fe73dee4680": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_963d23101b2244a7b5611a5f1d422ba8",
       "IPY_MODEL_d3321d3a55754146a03d34fa8e87b27e",
       "IPY_MODEL_dd65a939d7f14a7fa71e8c724e278e4e"
      ],
      "layout": "IPY_MODEL_93f358f852dd4b9d8dfc4e14bc85da13"
     }
    },
    "6f2574a24cb34f86837a2f605fb4f240": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71edaf7b5deb414fab8085de14d3bba3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8026ff65313f475494a9e832608b4506": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f2574a24cb34f86837a2f605fb4f240",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_44d94ab5f3784298baa5aab63c71f9b9",
      "value": "100%"
     }
    },
    "824f0b0594da456b8fb81b2ff57279ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93f358f852dd4b9d8dfc4e14bc85da13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "963d23101b2244a7b5611a5f1d422ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b92799d96032440dabd4ba36f9e11235",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4df4b81e949c48c7bf6997702beab34f",
      "value": "adapter_model.safetensors:â€‡"
     }
    },
    "b92799d96032440dabd4ba36f9e11235": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cba3099574974ee2a0efe97886ba379c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3321d3a55754146a03d34fa8e87b27e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50edb18a04794cb19055313b828e8b26",
      "max": 83115256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_71edaf7b5deb414fab8085de14d3bba3",
      "value": 83115256
     }
    },
    "da1ebe61cc1b46c598862e75dce760bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd65a939d7f14a7fa71e8c724e278e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0bdd86e18ac41938830a19de864404a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_14cc5f8d7f794c31b289a148654beb74",
      "value": "â€‡96.0M/?â€‡[00:01&lt;00:00,â€‡89.1MB/s]"
     }
    },
    "f0bdd86e18ac41938830a19de864404a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f39ce7858dcd4a2ebe9d028987ab7dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_219f11c70431466da22aa8aae51c74c6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da1ebe61cc1b46c598862e75dce760bc",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
