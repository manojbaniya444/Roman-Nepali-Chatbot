{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.2,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "index_ = 4\n",
    "for i in range(index_ + 1, index_ + 1 + 2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello in Hello World\n"
     ]
    }
   ],
   "source": [
    "if \"Hello\" in \"Hello World\":\n",
    "    print(\"Hello in Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align(data):\n",
    "    aligned_data = []\n",
    "    # iterate over each sample in json data\n",
    "    for sample in data:\n",
    "        print(f\"For Text: {sample[\"text\"]}\")\n",
    "        completed_tokens_index = []\n",
    "        text = sample[\"text\"] # text from the sample\n",
    "        entities = sample[\"entities\"] # all entities from sample text\n",
    "        tokens = text.split()\n",
    "        \n",
    "        labels = [\"O\"] * len(tokens)\n",
    "        \n",
    "        # looping through each entity in entities\n",
    "        for entity in entities:\n",
    "            entity_text = entity[\"text\"]\n",
    "            entity_label = entity[\"label\"]\n",
    "            entity_start = entity[\"start\"]\n",
    "            entity_end = entity[\"end\"]\n",
    "            print(completed_tokens_index)\n",
    "            # continue if the index is already assigned\n",
    "            # each token with index in a single sentence\n",
    "            for index, token in enumerate(tokens):\n",
    "                # if token is already aligned then continue\n",
    "                \n",
    "                # if token is in entity text then align entity\n",
    "                if token in entity_text and index not in completed_tokens_index:\n",
    "                    labels[index] = \"B-\" + entity_label\n",
    "                    # adding the completed index token to avoid re-writing\n",
    "                    completed_tokens_index.append(index)\n",
    "                    print(f\"Adding {index} to completed_tokens_index\")\n",
    "                    # if the entity text has more than one text in it\n",
    "                    # loop after the next token till all next tokens in it\n",
    "                    if len(entity_text.split()) > 1:\n",
    "                        for new_idx in range(index + 1, index + len(entity_text.split())):\n",
    "                            labels[new_idx] = \"I-\" + entity_label\n",
    "                            completed_tokens_index.append(new_idx)\n",
    "                            print(f\"Added new {new_idx} to completed_tokens_index\")\n",
    "                        \n",
    "        aligned_data.append((tokens, labels))\n",
    "        print(\"*******DONE FOR THE SAMPLE********************\\n\")\n",
    "            \n",
    "    return aligned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./labeled_data.json\", \"r\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Text: I want to buy Nike Air Max in size 9 for $120 Nike\n",
      "[]\n",
      "Adding 4 to completed_tokens_index\n",
      "Adding 12 to completed_tokens_index\n",
      "[4, 12]\n",
      "Adding 5 to completed_tokens_index\n",
      "Added new 6 to completed_tokens_index\n",
      "[4, 12, 5, 6]\n",
      "Adding 8 to completed_tokens_index\n",
      "Added new 9 to completed_tokens_index\n",
      "[4, 12, 5, 6, 8, 9]\n",
      "Adding 11 to completed_tokens_index\n",
      "[4, 12, 5, 6, 8, 9, 11]\n",
      "*******DONE FOR THE SAMPLE********************\n",
      "\n",
      "For Text: I want to buy Nike Air Max in size 9 for $120\n",
      "[]\n",
      "Adding 4 to completed_tokens_index\n",
      "[4]\n",
      "Adding 5 to completed_tokens_index\n",
      "Added new 6 to completed_tokens_index\n",
      "[4, 5, 6]\n",
      "Adding 8 to completed_tokens_index\n",
      "Added new 9 to completed_tokens_index\n",
      "[4, 5, 6, 8, 9]\n",
      "Adding 11 to completed_tokens_index\n",
      "*******DONE FOR THE SAMPLE********************\n",
      "\n",
      "For Text: Show me red Samsung Galaxy S21 phones\n",
      "[]\n",
      "Adding 4 to completed_tokens_index\n",
      "Added new 5 to completed_tokens_index\n",
      "[4, 5]\n",
      "Adding 2 to completed_tokens_index\n",
      "[4, 5, 2]\n",
      "Adding 6 to completed_tokens_index\n",
      "*******DONE FOR THE SAMPLE********************\n",
      "\n",
      "For Text: Show me red Samsung Galaxy S21 phones\n",
      "[]\n",
      "Adding 4 to completed_tokens_index\n",
      "Added new 5 to completed_tokens_index\n",
      "[4, 5]\n",
      "Adding 2 to completed_tokens_index\n",
      "[4, 5, 2]\n",
      "Adding 6 to completed_tokens_index\n",
      "*******DONE FOR THE SAMPLE********************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = tokenize_and_align(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Show', 'me', 'red', 'Samsung', 'Galaxy', 'S21', 'phones'],\n",
       " ['O', 'O', 'B-COLOR', 'O', 'B-PRODUCT', 'I-PRODUCT', 'B-CATEGORY'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['I',\n",
       "  'want',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'Nike',\n",
       "  'Air',\n",
       "  'Max',\n",
       "  'in',\n",
       "  'size',\n",
       "  '9',\n",
       "  'for',\n",
       "  '$120',\n",
       "  'Nike'],\n",
       " ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-BRAND',\n",
       "  'B-PRODUCT',\n",
       "  'I-PRODUCT',\n",
       "  'O',\n",
       "  'B-SIZE',\n",
       "  'I-SIZE',\n",
       "  'O',\n",
       "  'B-PRICE',\n",
       "  'B-BRAND'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Show', 'me', 'red', 'Samsung', 'Galaxy', 'S21', 'phones'],\n",
       " ['O', 'O', 'B-COLOR', 'O', 'B-PRODUCT', 'I-PRODUCT', 'B-CATEGORY'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
